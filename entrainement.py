# Importation des biblioth√®ques n√©cessaires
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (confusion_matrix, accuracy_score, precision_score, recall_score, 
                             f1_score, roc_auc_score, roc_curve, auc, 
                             precision_recall_curve, average_precision_score, classification_report)
import warnings
warnings.filterwarnings('ignore')

# Mod√®les de Machine Learning
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB

# Pour la gestion du d√©s√©quilibre
from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE
from imblearn.under_sampling import RandomUnderSampler, TomekLinks
from imblearn.combine import SMOTETomek, SMOTEENN

# Pour sauvegarder le mod√®le
import joblib

print("="*80)
print("D√âTECTION DE FRAUDE BANCAIRE - MACHINE LEARNING")
print("="*80)

# ============================================================================
# T√ÇCHE 1 : CHARGEMENT DES DONN√âES
# ============================================================================
print("\n[T√ÇCHE 1] Chargement des donn√©es...")

df = pd.read_csv('./static/data/creditcarddata.csv')
print(f"‚úì Donn√©es charg√©es avec succ√®s : {df.shape[0]} lignes, {df.shape[1]} colonnes")
print("\nAper√ßu des donn√©es :")
print(df.head())
print("\nInformations sur les donn√©es :")
print(df.info())
print("\nStatistiques descriptives :")
print(df.describe())

# ============================================================================
# T√ÇCHE 2 : LISTE DES MOD√àLES POUR R√âSOUDRE LE PROBL√àME
# ============================================================================
print("\n" + "="*80)
print("[T√ÇCHE 2] Mod√®les de classification pour la d√©tection de fraude")
print("="*80)

modeles_liste = [
    "1. R√©gression Logistique (Logistic Regression)",
    "2. Arbre de D√©cision (Decision Tree)",
    "3. For√™t Al√©atoire (Random Forest)",
    "4. Gradient Boosting",
    "5. Support Vector Machine (SVM)",
    "6. K-Nearest Neighbors (KNN)",
    "7. Naive Bayes"
]

for modele in modeles_liste:
    print(f"  {modele}")

# ============================================================================
# T√ÇCHE 3 : PR√âPARATION DES DONN√âES
# ============================================================================
print("\n" + "="*80)
print("[T√ÇCHE 3] Pr√©paration des donn√©es")
print("="*80)

# 3.1 V√©rification des valeurs manquantes
print("\n3.1 V√©rification des valeurs manquantes :")
valeurs_manquantes = df.isnull().sum()
print(valeurs_manquantes)
if valeurs_manquantes.sum() > 0:
    print("‚ö† Valeurs manquantes d√©tect√©es. Traitement en cours...")
    df = df.dropna()
    print(f"‚úì Valeurs manquantes supprim√©es. Nouvelles dimensions : {df.shape}")
else:
    print("‚úì Aucune valeur manquante d√©tect√©e")

# 3.2 V√©rification des doublons
print("\n3.2 V√©rification des doublons :")
nb_doublons = df.duplicated().sum()
print(f"Nombre de doublons : {nb_doublons}")
if nb_doublons > 0:
    print("‚ö† Doublons d√©tect√©s. Suppression en cours...")
    df = df.drop_duplicates()
    print(f"‚úì Doublons supprim√©s. Nouvelles dimensions : {df.shape}")
else:
    print("‚úì Aucun doublon d√©tect√©")

# 3.3 V√©rification et traitement des valeurs aberrantes (outliers)
print("\n3.3 V√©rification et traitement des valeurs aberrantes :")
colonnes_numeriques = df.select_dtypes(include=[np.number]).columns.drop('PotentialFraud')
print(f"Colonnes num√©riques analys√©es : {list(colonnes_numeriques)}")

# Fonction pour d√©tecter les outliers avec IQR
def detect_outliers_iqr(data, column):
    Q1 = data[column].quantile(0.25)
    Q3 = data[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = (data[column] < lower_bound) | (data[column] > upper_bound)
    return outliers, lower_bound, upper_bound

# Fonction pour calculer le Z-score
def calculate_zscore(data, column):
    mean = data[column].mean()
    std = data[column].std()
    zscore = (data[column] - mean) / std
    return zscore

# Analyse des outliers pour chaque colonne num√©rique
print("\nAnalyse d√©taill√©e des valeurs aberrantes :")
outliers_info = {}

for col in colonnes_numeriques:
    outliers_mask, lower, upper = detect_outliers_iqr(df, col)
    nb_outliers = outliers_mask.sum()
    pct_outliers = (nb_outliers / len(df)) * 100
    
    print(f"\n  {col} :")
    print(f"    - Nombre d'outliers (IQR) : {nb_outliers} ({pct_outliers:.2f}%)")
    print(f"    - Limites : [{lower:.2f}, {upper:.2f}]")
    print(f"    - Min: {df[col].min():.2f}, Max: {df[col].max():.2f}")
    
    outliers_info[col] = {
        'count': nb_outliers,
        'percentage': pct_outliers,
        'lower': lower,
        'upper': upper
    }

# Traitement sp√©cifique pour TransactionAmount (approche recommand√©e)
print("\n‚ö† Traitement des outliers pour TransactionAmount :")
print("  ‚Üí Cr√©ation de features enrichies au lieu de supprimer les outliers")

# 1. Cr√©er un indicateur de transaction √©lev√©e (> 99e percentile)
percentile_99 = df['TransactionAmount'].quantile(0.99)
df['TransactionAmount_is_high'] = (df['TransactionAmount'] > percentile_99).astype(int)
print(f"  ‚úì Feature 'TransactionAmount_is_high' cr√©√©e (seuil: {percentile_99:.2f})")
print(f"    Transactions √©lev√©es d√©tect√©es : {df['TransactionAmount_is_high'].sum()}")

# 2. Calculer le Z-score comme feature
df['TransactionAmount_zscore'] = calculate_zscore(df, 'TransactionAmount')
print(f"  ‚úì Feature 'TransactionAmount_zscore' cr√©√©e")
print(f"    Z-score min: {df['TransactionAmount_zscore'].min():.2f}, max: {df['TransactionAmount_zscore'].max():.2f}")

# 3. Transformation logarithmique pour r√©duire l'asym√©trie
df['TransactionAmount_log'] = np.log1p(df['TransactionAmount'])
print(f"  ‚úì Feature 'TransactionAmount_log' cr√©√©e (log1p transformation)")

# 4. Cr√©er des cat√©gories de montant
bins = [0, 10, 50, 100, 500, np.inf]
labels = ['Tr√®s faible', 'Faible', 'Moyen', '√âlev√©', 'Tr√®s √©lev√©']
df['TransactionAmount_category'] = pd.cut(df['TransactionAmount'], bins=bins, labels=labels)
df['TransactionAmount_category'] = df['TransactionAmount_category'].cat.codes
print(f"  ‚úì Feature 'TransactionAmount_category' cr√©√©e (5 cat√©gories)")

# V√©rification des valeurs impossibles pour Age
print("\n  V√©rification de l'√¢ge :")
age_invalid = ((df['Age'] < 0) | (df['Age'] > 120)).sum()
if age_invalid > 0:
    print(f"  ‚ö† {age_invalid} √¢ges invalides d√©tect√©s. Correction en cours...")
    df = df[(df['Age'] >= 0) & (df['Age'] <= 120)]
    print(f"  ‚úì √Çges invalides supprim√©s")
else:
    print(f"  ‚úì Tous les √¢ges sont valides (0-120 ans)")

# Visualisation de l'impact de la transformation logarithmique

# Graphique 1 : Distribution originale
plt.figure(figsize=(10, 6))
plt.hist(df['TransactionAmount'], bins=50, color='steelblue', edgecolor='black', alpha=0.7)
plt.title('Distribution originale de TransactionAmount', fontsize=14, fontweight='bold')
plt.xlabel('Montant', fontsize=12)
plt.ylabel('Fr√©quence', fontsize=12)
plt.axvline(percentile_99, color='red', linestyle='--', linewidth=2, label=f'99e percentile ({percentile_99:.2f})')
plt.legend(fontsize=10)
plt.grid(alpha=0.3)
plt.tight_layout()
#plt.savefig('03_distribution_originale.png', dpi=300, bbox_inches='tight')
plt.close()
print("‚úì Graphique sauvegard√© : 03_distribution_originale.png")

# Graphique 2 : Distribution log-transform√©e
plt.figure(figsize=(10, 6))
plt.hist(df['TransactionAmount_log'], bins=50, color='green', edgecolor='black', alpha=0.7)
plt.title('Distribution log-transform√©e de TransactionAmount', fontsize=14, fontweight='bold')
plt.xlabel('log(Montant + 1)', fontsize=12)
plt.ylabel('Fr√©quence', fontsize=12)
plt.grid(alpha=0.3)
plt.tight_layout()
#plt.savefig('04_distribution_log.png', dpi=300, bbox_inches='tight')
plt.close()
print("‚úì Graphique sauvegard√© : 04_distribution_log.png")

# Graphique 3 : Distribution des Z-scores
plt.figure(figsize=(10, 6))
plt.hist(df['TransactionAmount_zscore'], bins=50, color='orange', edgecolor='black', alpha=0.7)
plt.title('Distribution des Z-scores de TransactionAmount', fontsize=14, fontweight='bold')
plt.xlabel('Z-score', fontsize=12)
plt.ylabel('Fr√©quence', fontsize=12)
plt.axvline(-3, color='red', linestyle='--', linewidth=2, label='Seuil -3')
plt.axvline(3, color='red', linestyle='--', linewidth=2, label='Seuil +3')
plt.legend(fontsize=10)
plt.grid(alpha=0.3)
plt.tight_layout()
#plt.savefig('05_distribution_zscore.png', dpi=300, bbox_inches='tight')
plt.close()
print("‚úì Graphique sauvegard√© : 05_distribution_zscore.png")

print("\n‚úì Traitement des valeurs aberrantes termin√©")
print(f"  Dimensions finales : {df.shape}")

# 3.4 Analyse du d√©s√©quilibre de classes
print("\n3.4 Analyse du d√©s√©quilibre de classes :")
distribution_classe = df['PotentialFraud'].value_counts()
print(distribution_classe)

taux_fraude = distribution_classe[1]/len(df)*100
taux_non_fraude = distribution_classe[0]/len(df)*100

print(f"\nProportion de fraudes : {taux_fraude:.2f}%")
print(f"Proportion de non-fraudes : {taux_non_fraude:.2f}%")
print(f"Ratio : 1 fraude pour {distribution_classe[0]/distribution_classe[1]:.1f} non-fraudes")

# Visualisation du d√©s√©quilibre - Graphique 1 : Bar plot
plt.figure(figsize=(8, 6))
distribution_classe.plot(kind='bar', color=['green', 'red'])
plt.title('Distribution des classes (AVANT r√©√©quilibrage)', fontsize=14, fontweight='bold')
plt.xlabel('PotentialFraud', fontsize=12)
plt.ylabel('Nombre d\'observations', fontsize=12)
plt.xticks(rotation=0)
plt.grid(axis='y', alpha=0.3)
plt.tight_layout()
#plt.savefig('01_distribution_classes_barplot_AVANT.png', dpi=300, bbox_inches='tight')
plt.close()
print("‚úì Graphique sauvegard√© : 01_distribution_classes_barplot_AVANT.png")

# Visualisation du d√©s√©quilibre - Graphique 2 : Pie chart
plt.figure(figsize=(8, 8))
plt.pie(distribution_classe, labels=['Non-Fraude', 'Fraude'], autopct='%1.1f%%', 
        colors=['green', 'red'], startangle=90, textprops={'fontsize': 12},
        explode=(0, 0.1))
plt.title('Proportion des classes (AVANT r√©√©quilibrage)', fontsize=14, fontweight='bold')
plt.tight_layout()
#plt.savefig('02_distribution_classes_piechart_AVANT.png', dpi=300, bbox_inches='tight')
plt.close()
print("‚úì Graphique sauvegard√© : 02_distribution_classes_piechart_AVANT.png")

# D√©tection du d√©s√©quilibre
if taux_fraude < 30:
    print(f"\n‚ö†Ô∏è D√âS√âQUILIBRE IMPORTANT D√âTECT√â : Seulement {taux_fraude:.2f}% de fraudes")
    print("   ‚Üí Le r√©√©quilibrage sera appliqu√© apr√®s la division train/test")
    desequilibre = True
else:
    desequilibre = False

# ============================================================================
# T√ÇCHE 4 : DIVISION DES DONN√âES (70% train, 30% test)
# ============================================================================
print("\n" + "="*80)
print("[T√ÇCHE 4] Division des donn√©es")
print("="*80)

# S√©paration des features et de la cible
X = df.drop('PotentialFraud', axis=1)
y = df['PotentialFraud']

# Division train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

print(f"‚úì Donn√©es d'entra√Ænement : {X_train.shape[0]} observations ({70}%)")
print(f"‚úì Donn√©es de test : {X_test.shape[0]} observations ({30}%)")
print(f"\nDistribution dans le train AVANT r√©√©quilibrage :")
print(y_train.value_counts())
print(f"\nDistribution dans le test :")
print(y_test.value_counts())

# ============================================================================
# R√â√âQUILIBRAGE DU DATASET (CRITIQUE POUR LA D√âTECTION DE FRAUDE)
# ============================================================================
print("\n" + "="*80)
print("R√â√âQUILIBRAGE DU DATASET")
print("="*80)

if desequilibre:
    print("\n‚ö†Ô∏è Application du r√©√©quilibrage sur les donn√©es d'entra√Ænement...")
    print("   (Les donn√©es de test ne sont PAS modifi√©es pour une √©valuation r√©aliste)")
    
    # M√©thode 1: SMOTE (Synthetic Minority Over-sampling Technique)
    print("\nüìä M√©thode utilis√©e : SMOTE + Tomek Links (SMOTETomek)")
    print("   - SMOTE : Cr√©e des √©chantillons synth√©tiques de la classe minoritaire")
    print("   - Tomek Links : Supprime les √©chantillons ambigus √† la fronti√®re")
    
    # Appliquer SMOTETomek (combinaison de sur-√©chantillonnage et nettoyage)
    smote_tomek = SMOTETomek(
        smote=SMOTE(sampling_strategy='auto', random_state=42, k_neighbors=5),
        random_state=42
    )
    
    X_train_resampled, y_train_resampled = smote_tomek.fit_resample(X_train, y_train)
    
    print(f"\n‚úÖ R√©√©quilibrage termin√© !")
    print(f"\n   AVANT r√©√©quilibrage : {len(X_train)} √©chantillons")
    print(f"   APR√àS r√©√©quilibrage : {len(X_train_resampled)} √©chantillons")
    
    print(f"\n   Distribution AVANT :")
    print(f"      Non-fraude : {(y_train == 0).sum()} ({(y_train == 0).sum()/len(y_train)*100:.1f}%)")
    print(f"      Fraude     : {(y_train == 1).sum()} ({(y_train == 1).sum()/len(y_train)*100:.1f}%)")
    
    print(f"\n   Distribution APR√àS :")
    print(f"      Non-fraude : {(y_train_resampled == 0).sum()} ({(y_train_resampled == 0).sum()/len(y_train_resampled)*100:.1f}%)")
    print(f"      Fraude     : {(y_train_resampled == 1).sum()} ({(y_train_resampled == 1).sum()/len(y_train_resampled)*100:.1f}%)")
    
    # Utiliser les donn√©es r√©√©quilibr√©es pour l'entra√Ænement
    X_train = X_train_resampled
    y_train = y_train_resampled
    
    # Visualisation APR√àS r√©√©quilibrage
    plt.figure(figsize=(8, 6))
    y_train.value_counts().plot(kind='bar', color=['green', 'red'])
    plt.title('Distribution des classes (APR√àS r√©√©quilibrage)', fontsize=14, fontweight='bold')
    plt.xlabel('PotentialFraud', fontsize=12)
    plt.ylabel('Nombre d\'observations', fontsize=12)
    plt.xticks(rotation=0)
    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    #plt.savefig('01b_distribution_classes_barplot_APRES.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("\n‚úì Graphique sauvegard√© : 01b_distribution_classes_barplot_APRES.png")
    
    # Comparaison avant/apr√®s
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # Avant
    distribution_classe.plot(kind='bar', color=['green', 'red'], ax=axes[0])
    axes[0].set_title('AVANT r√©√©quilibrage', fontsize=12, fontweight='bold')
    axes[0].set_xlabel('PotentialFraud')
    axes[0].set_ylabel('Nombre')
    axes[0].tick_params(axis='x', rotation=0)
    
    # Apr√®s
    y_train.value_counts().plot(kind='bar', color=['green', 'red'], ax=axes[1])
    axes[1].set_title('APR√àS r√©√©quilibrage (Train)', fontsize=12, fontweight='bold')
    axes[1].set_xlabel('PotentialFraud')
    axes[1].set_ylabel('Nombre')
    axes[1].tick_params(axis='x', rotation=0)
    
    plt.suptitle('Impact du r√©√©quilibrage SMOTETomek', fontsize=14, fontweight='bold')
    plt.tight_layout()
    #plt.savefig('01c_comparaison_reequilibrage.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("‚úì Graphique sauvegard√© : 01c_comparaison_reequilibrage.png")

else:
    print("\n‚úÖ Dataset suffisamment √©quilibr√©, pas de r√©√©quilibrage n√©cessaire")

# ============================================================================
# NORMALISATION DES DONN√âES
# ============================================================================
print("\n" + "="*80)
print("NORMALISATION DES DONN√âES")
print("="*80)

print("\nPlusieurs m√©thodes de normalisation disponibles :")
print("  1. StandardScaler : (X - mean) / std ‚Üí Distribution N(0,1)")
print("  2. MinMaxScaler : (X - min) / (max - min) ‚Üí √âchelle [0,1]")
print("  3. RobustScaler : Utilise la m√©diane et IQR ‚Üí Robuste aux outliers")

# Afficher les statistiques avant normalisation
print("\nStatistiques AVANT normalisation (√©chantillon) :")
print(X_train[['Age', 'TransactionAmount', 'TransactionAmount_log']].describe())

# M√©thode 1 : StandardScaler (recommand√© pour la plupart des mod√®les)
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler

print("\n‚Üí Application de StandardScaler (m√©thode principale)")
scaler_standard = StandardScaler()
X_train_standard = scaler_standard.fit_transform(X_train)
X_test_standard = scaler_standard.transform(X_test)
print("  ‚úì StandardScaler appliqu√©")

# M√©thode 2 : RobustScaler (pour donn√©es avec outliers)
print("\n‚Üí Application de RobustScaler (robuste aux outliers)")
scaler_robust = RobustScaler()
X_train_robust = scaler_robust.fit_transform(X_train)
X_test_robust = scaler_robust.transform(X_test)
print("  ‚úì RobustScaler appliqu√©")

# M√©thode 3 : MinMaxScaler (pour r√©seaux de neurones)
print("\n‚Üí Application de MinMaxScaler (√©chelle 0-1)")
scaler_minmax = MinMaxScaler()
X_train_minmax = scaler_minmax.fit_transform(X_train)
X_test_minmax = scaler_minmax.transform(X_test)
print("  ‚úì MinMaxScaler appliqu√©")

# Utiliser StandardScaler par d√©faut
X_train_scaled = X_train_standard
X_test_scaled = X_test_standard
scaler = scaler_standard

print("\n‚úì Normalisation principale : StandardScaler s√©lectionn√©")

# Afficher les statistiques apr√®s normalisation
X_train_scaled_df = pd.DataFrame(
    X_train_scaled, 
    columns=X_train.columns
)
print("\nStatistiques APR√àS normalisation (√©chantillon) :")
print(X_train_scaled_df[['Age', 'TransactionAmount', 'TransactionAmount_log']].describe())

# Visualisation de l'effet de la normalisation
colonnes_viz = ['Age', 'TransactionAmount', 'TransactionAmount_log']

for idx, col in enumerate(colonnes_viz):
    # Graphique AVANT normalisation
    plt.figure(figsize=(10, 6))
    plt.hist(X_train[col], bins=30, color='steelblue', alpha=0.7, edgecolor='black')
    plt.title(f'{col} - AVANT normalisation', fontsize=14, fontweight='bold')
    plt.xlabel('Valeur', fontsize=12)
    plt.ylabel('Fr√©quence', fontsize=12)
    plt.grid(alpha=0.3)
    plt.tight_layout()
    #plt.savefig(f'06_normalisation_avant_{col}.png', dpi=300, bbox_inches='tight')
    plt.close()
    print(f"‚úì Graphique sauvegard√© : 06_normalisation_avant_{col}.png")
    
    # Graphique APR√àS normalisation
    plt.figure(figsize=(10, 6))
    col_index = list(X_train.columns).index(col)
    plt.hist(X_train_scaled[:, col_index], bins=30, color='green', alpha=0.7, edgecolor='black')
    plt.title(f'{col} - APR√àS normalisation (StandardScaler)', fontsize=14, fontweight='bold')
    plt.xlabel('Valeur normalis√©e', fontsize=12)
    plt.ylabel('Fr√©quence', fontsize=12)
    plt.grid(alpha=0.3)
    plt.tight_layout()
    #plt.savefig(f'07_normalisation_apres_{col}.png', dpi=300, bbox_inches='tight')
    plt.close()
    print(f"‚úì Graphique sauvegard√© : 07_normalisation_apres_{col}.png")

print("\n" + "="*80)

# ============================================================================
# T√ÇCHE 5 : CR√âATION ET ENTRA√éNEMENT DES MOD√àLES
# ============================================================================
print("\n" + "="*80)
print("[T√ÇCHE 5] Entra√Ænement des mod√®les")
print("="*80)

# Dictionnaire des mod√®les (avec class_weight pour g√©rer le d√©s√©quilibre)
print("\nüí° Note: Les mod√®les utilisent class_weight='balanced' pour mieux d√©tecter les fraudes")

modeles = {
    'Logistic Regression': LogisticRegression(
        random_state=42, 
        max_iter=1000, 
        class_weight='balanced'  # P√©nalise plus les erreurs sur la classe minoritaire
    ),
    'Decision Tree': DecisionTreeClassifier(
        random_state=42, 
        class_weight='balanced'
    ),
    'Random Forest': RandomForestClassifier(
        random_state=42, 
        n_estimators=100, 
        class_weight='balanced'  # Important pour la fraude
    ),
    'Gradient Boosting': GradientBoostingClassifier(
        random_state=42, 
        n_estimators=100
        # Note: GradientBoosting n'a pas class_weight, mais SMOTE compense
    ),
    'SVM': SVC(
        random_state=42, 
        kernel='rbf', 
        class_weight='balanced',
        probability=True  # N√©cessaire pour predict_proba
    ),
    'KNN': KNeighborsClassifier(
        n_neighbors=5
        # Note: KNN n'a pas class_weight, mais SMOTE compense
    ),
    'Naive Bayes': GaussianNB()
    # Note: GaussianNB n'a pas class_weight, mais SMOTE compense
}

# Entra√Ænement des mod√®les
modeles_entraines = {}
for nom, modele in modeles.items():
    print(f"\n‚Üí Entra√Ænement de {nom}...")
    modele.fit(X_train_scaled, y_train)
    modeles_entraines[nom] = modele
    print(f"  ‚úì {nom} entra√Æn√© avec succ√®s")

# ============================================================================
# T√ÇCHE 6 : √âVALUATION DES MOD√àLES (Matrices de confusion)
# ============================================================================
print("\n" + "="*80)
print("[T√ÇCHE 6] √âvaluation des mod√®les - Matrices de confusion")
print("="*80)

# Cr√©ation des matrices de confusion individuelles
for idx, (nom, modele) in enumerate(modeles_entraines.items()):
    y_pred = modele.predict(X_test_scaled)
    cm = confusion_matrix(y_test, y_pred)
    
    # Cr√©er une figure pour chaque matrice
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['Non-Fraude', 'Fraude'],
                yticklabels=['Non-Fraude', 'Fraude'],
                cbar_kws={'label': 'Nombre de pr√©dictions'})
    plt.title(f'Matrice de confusion - {nom}', fontsize=14, fontweight='bold')
    plt.ylabel('Vraie classe', fontsize=12)
    plt.xlabel('Classe pr√©dite', fontsize=12)
    plt.tight_layout()
    
    # Sauvegarder avec un nom num√©rot√©
    numero = 8 + idx  # Commence √† 08 apr√®s les graphiques de normalisation
    nom_fichier = f'{numero:02d}_matrice_confusion_{nom.replace(" ", "_")}.png'
    #plt.savefig(nom_fichier, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"‚úì Matrice de confusion sauvegard√©e : {nom_fichier}")
    
    # Analyse de la matrice
    tn, fp, fn, tp = cm.ravel()
    print(f"   TN={tn}, FP={fp}, FN={fn}, TP={tp}")

# ============================================================================
# T√ÇCHE 7 : CALCUL DES M√âTRIQUES (Accuracy, Pr√©cision, Rappel, F1, ROC-AUC)
# ============================================================================
print("\n" + "="*80)
print("[T√ÇCHE 7] Calcul des m√©triques de performance")
print("="*80)

resultats = []
courbes_roc = {}
courbes_pr = {}

for nom, modele in modeles_entraines.items():
    y_pred = modele.predict(X_test_scaled)
    
    # Calculer les probabilit√©s si le mod√®le le supporte
    if hasattr(modele, 'predict_proba'):
        y_pred_proba = modele.predict_proba(X_test_scaled)[:, 1]
    elif hasattr(modele, 'decision_function'):
        y_pred_proba = modele.decision_function(X_test_scaled)
    else:
        y_pred_proba = y_pred  # Fallback
    
    # Calcul des m√©triques de base
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, zero_division=0)
    rec = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    
    # Calcul du ROC-AUC
    try:
        roc_auc = roc_auc_score(y_test, y_pred_proba)
        # Calculer la courbe ROC pour visualisation
        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
        courbes_roc[nom] = (fpr, tpr, roc_auc)
    except:
        roc_auc = np.nan
        courbes_roc[nom] = None
    
    # Calcul de l'Average Precision (pour courbe Precision-Recall)
    try:
        avg_precision = average_precision_score(y_test, y_pred_proba)
        # Calculer la courbe Precision-Recall
        precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba)
        courbes_pr[nom] = (recall_curve, precision_curve, avg_precision)
    except:
        avg_precision = np.nan
        courbes_pr[nom] = None
    
    resultats.append({
        'Mod√®le': nom,
        'Accuracy': acc,
        'Pr√©cision': prec,
        'Rappel': rec,
        'F1-Score': f1,
        'ROC-AUC': roc_auc,
        'Avg Precision': avg_precision
    })
    
    print(f"\n{nom} :")
    print(f"  Accuracy        : {acc:.4f} ({acc*100:.2f}%)")
    print(f"  Pr√©cision       : {prec:.4f} ({prec*100:.2f}%)")
    print(f"  Rappel (Recall) : {rec:.4f} ({rec*100:.2f}%)")
    print(f"  F1-Score        : {f1:.4f} ({f1*100:.2f}%)")
    print(f"  ROC-AUC         : {roc_auc:.4f}" if not np.isnan(roc_auc) else "  ROC-AUC         : N/A")
    print(f"  Avg Precision   : {avg_precision:.4f}" if not np.isnan(avg_precision) else "  Avg Precision   : N/A")

# ============================================================================
# T√ÇCHE 8 : COMPARAISON DES MOD√àLES
# ============================================================================
print("\n" + "="*80)
print("[T√ÇCHE 8] Comparaison des mod√®les")
print("="*80)

df_resultats = pd.DataFrame(resultats)

# Pour la d√©tection de fraude, on trie par RAPPEL (d√©tecter un max de fraudes)
# puis par F1-Score pour l'√©quilibre
df_resultats = df_resultats.sort_values(['Rappel', 'F1-Score'], ascending=[False, False])

print("\nTableau comparatif des performances (tri√© par Rappel) :")
print(df_resultats.to_string(index=False))

print("\nüí° Pour la d√©tection de FRAUDE :")
print("   - RAPPEL √©lev√© = D√©tecte un maximum de vraies fraudes (priorit√© #1)")
print("   - PR√âCISION √©lev√©e = Peu de fausses alertes")
print("   - F1-Score = √âquilibre entre les deux")

# Visualisation comparative - Graphiques individuels
metriques = ['Accuracy', 'Pr√©cision', 'Rappel', 'F1-Score', 'ROC-AUC']
numero_base = 15

for idx, metrique in enumerate(metriques):
    plt.figure(figsize=(12, 6))
    
    # Filtrer les valeurs NaN pour ROC-AUC
    df_plot = df_resultats[['Mod√®le', metrique]].dropna()
    df_plot_sorted = df_plot.sort_values(metrique, ascending=True)
    
    bars = plt.barh(df_plot_sorted['Mod√®le'], df_plot_sorted[metrique], color='steelblue')
    plt.title(f'Comparaison des mod√®les - {metrique}', fontsize=14, fontweight='bold')
    plt.xlabel(metrique, fontsize=12)
    plt.ylabel('Mod√®le', fontsize=12)
    plt.xlim([0, 1.1])
    plt.grid(axis='x', alpha=0.3)
    
    # Ajouter les valeurs sur les barres
    for i, (bar, value) in enumerate(zip(bars, df_plot_sorted[metrique])):
        plt.text(value + 0.01, i, f'{value:.3f}', va='center', fontsize=10)
    
    plt.tight_layout()
    numero = numero_base + idx
    #plt.savefig(f'{numero:02d}_comparaison_{metrique.lower().replace("-", "_")}.png', dpi=300, bbox_inches='tight')
    plt.close()
    print(f"‚úì Graphique sauvegard√© : {numero:02d}_comparaison_{metrique.lower().replace('-', '_')}.png")

# ============================================================================
# COURBES ROC (Receiver Operating Characteristic)
# ============================================================================
print("\n" + "="*80)
print("COURBES ROC (Receiver Operating Characteristic)")
print("="*80)

# Graphique combin√© de toutes les courbes ROC
plt.figure(figsize=(10, 8))
for nom, data in courbes_roc.items():
    if data is not None:
        fpr, tpr, roc_auc = data
        plt.plot(fpr, tpr, lw=2, label=f'{nom} (AUC = {roc_auc:.3f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Al√©atoire (AUC = 0.500)')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Taux de Faux Positifs (FPR)', fontsize=12)
plt.ylabel('Taux de Vrais Positifs (TPR)', fontsize=12)
plt.title('Courbes ROC - Tous les mod√®les', fontsize=14, fontweight='bold')
plt.legend(loc="lower right", fontsize=9)
plt.grid(alpha=0.3)
plt.tight_layout()
#plt.savefig('20_courbes_roc_tous_modeles.png', dpi=300, bbox_inches='tight')
plt.close()
print("‚úì Graphique sauvegard√© : 20_courbes_roc_tous_modeles.png")

# Courbes ROC individuelles
numero = 21
for nom, data in courbes_roc.items():
    if data is not None:
        fpr, tpr, roc_auc = data
        plt.figure(figsize=(8, 6))
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {roc_auc:.3f})')
        plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Al√©atoire (AUC = 0.500)')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('Taux de Faux Positifs (FPR)', fontsize=12)
        plt.ylabel('Taux de Vrais Positifs (TPR)', fontsize=12)
        plt.title(f'Courbe ROC - {nom}', fontsize=14, fontweight='bold')
        plt.legend(loc="lower right")
        plt.grid(alpha=0.3)
        plt.tight_layout()
        #plt.savefig(f'{numero:02d}_courbe_roc_{nom.replace(" ", "_")}.png', dpi=300, bbox_inches='tight')
        plt.close()
        print(f"‚úì Courbe ROC sauvegard√©e : {numero:02d}_courbe_roc_{nom.replace(' ', '_')}.png")
        numero += 1

# ============================================================================
# COURBES PRECISION-RECALL
# ============================================================================
print("\n" + "="*80)
print("COURBES PRECISION-RECALL")
print("="*80)

# Graphique combin√© de toutes les courbes Precision-Recall
plt.figure(figsize=(10, 8))
for nom, data in courbes_pr.items():
    if data is not None:
        recall_curve, precision_curve, avg_precision = data
        plt.plot(recall_curve, precision_curve, lw=2, 
                label=f'{nom} (AP = {avg_precision:.3f})')

plt.xlabel('Rappel (Recall)', fontsize=12)
plt.ylabel('Pr√©cision', fontsize=12)
plt.title('Courbes Pr√©cision-Rappel - Tous les mod√®les', fontsize=14, fontweight='bold')
plt.legend(loc="lower left", fontsize=9)
plt.grid(alpha=0.3)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.tight_layout()
#plt.savefig('28_courbes_precision_recall_tous_modeles.png', dpi=300, bbox_inches='tight')
plt.close()
print("‚úì Graphique sauvegard√© : 28_courbes_precision_recall_tous_modeles.png")

# Courbes Precision-Recall individuelles
numero = 29
for nom, data in courbes_pr.items():
    if data is not None:
        recall_curve, precision_curve, avg_precision = data
        plt.figure(figsize=(8, 6))
        plt.plot(recall_curve, precision_curve, color='blue', lw=2, 
                label=f'PR (AP = {avg_precision:.3f})')
        plt.xlabel('Rappel (Recall)', fontsize=12)
        plt.ylabel('Pr√©cision', fontsize=12)
        plt.title(f'Courbe Pr√©cision-Rappel - {nom}', fontsize=14, fontweight='bold')
        plt.legend(loc="lower left")
        plt.grid(alpha=0.3)
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.tight_layout()
        #plt.savefig(f'{numero:02d}_courbe_pr_{nom.replace(" ", "_")}.png', dpi=300, bbox_inches='tight')
        plt.close()
        print(f"‚úì Courbe PR sauvegard√©e : {numero:02d}_courbe_pr_{nom.replace(' ', '_')}.png")
        numero += 1

# Identification du meilleur mod√®le (bas√© sur le Rappel pour la fraude)
meilleur_modele_nom = df_resultats.iloc[0]['Mod√®le']
meilleur_rappel = df_resultats.iloc[0]['Rappel']
meilleur_f1 = df_resultats.iloc[0]['F1-Score']
meilleur_roc_auc = df_resultats.iloc[0]['ROC-AUC']

print(f"\n{'='*80}")
print(f"üèÜ MEILLEUR MOD√àLE POUR LA D√âTECTION DE FRAUDE : {meilleur_modele_nom}")
print(f"   Rappel (Recall) : {meilleur_rappel:.4f} ({meilleur_rappel*100:.2f}%) - D√©tecte {meilleur_rappel*100:.0f}% des fraudes")
print(f"   F1-Score        : {meilleur_f1:.4f} ({meilleur_f1*100:.2f}%)")
print(f"   ROC-AUC         : {meilleur_roc_auc:.4f}" if not np.isnan(meilleur_roc_auc) else "   ROC-AUC         : N/A")
print(f"{'='*80}")

# ============================================================================
# T√ÇCHE 9 : SAUVEGARDE DU MEILLEUR MOD√àLE
# ============================================================================
print("\n" + "="*80)
print("[T√ÇCHE 9] Sauvegarde du meilleur mod√®le")
print("="*80)

meilleur_modele = modeles_entraines[meilleur_modele_nom]

# Sauvegarder le mod√®le, le scaler et les statistiques d'entra√Ænement
joblib.dump(meilleur_modele, 'ml/model.pkl')
joblib.dump(scaler, 'ml/scaler.pkl')

# Sauvegarder les statistiques pour garantir la coh√©rence lors des pr√©dictions
train_stats = {
    'percentile_99': df['TransactionAmount'].quantile(0.99),
    'mean': df['TransactionAmount'].mean(),
    'std': df['TransactionAmount'].std()
}
joblib.dump(train_stats, 'ml/train_stats.pkl')

print(f"‚úì Mod√®le sauvegard√© : ml/model.pkl")
print(f"‚úì Scaler sauvegard√© : ml/scaler.pkl")
print(f"‚úì Statistiques sauvegard√©es : ml/train_stats.pkl")
# Test de chargement
modele_charge = joblib.load('ml/model.pkl')
print(f"‚úì Test de chargement r√©ussi")

print("\n" + "="*80)
print("TRAITEMENT TERMIN√â AVEC SUCC√àS !")
print("="*80)
print("\nFichiers g√©n√©r√©s :")
print("\nüìä GRAPHIQUES DE DISTRIBUTION :")
print("  01. distribution_classes_barplot.png - Distribution en barres")
print("  02. distribution_classes_piechart.png - Distribution en camembert")

print("\nüîç GRAPHIQUES D'ANALYSE DES OUTLIERS :")
print("  03. distribution_originale.png - Distribution originale de TransactionAmount")
print("  04. distribution_log.png - Distribution log-transform√©e")
print("  05. distribution_zscore.png - Distribution des Z-scores")

print("\n‚öñÔ∏è GRAPHIQUES DE NORMALISATION (Avant/Apr√®s) :")
print("  06. normalisation_avant_Age.png")
print("  07. normalisation_apres_Age.png")
print("  06. normalisation_avant_TransactionAmount.png")
print("  07. normalisation_apres_TransactionAmount.png")
print("  06. normalisation_avant_TransactionAmount_log.png")
print("  07. normalisation_apres_TransactionAmount_log.png")

print("\nüìà MATRICES DE CONFUSION (par mod√®le) :")
print("  08. matrice_confusion_Logistic_Regression.png")
print("  09. matrice_confusion_Decision_Tree.png")
print("  10. matrice_confusion_Random_Forest.png")
print("  11. matrice_confusion_Gradient_Boosting.png")
print("  12. matrice_confusion_SVM.png")
print("  13. matrice_confusion_KNN.png")
print("  14. matrice_confusion_Naive_Bayes.png")

print("\nüìä COMPARAISONS DES MOD√àLES (M√©triques) :")
print("  15. comparaison_accuracy.png")
print("  16. comparaison_pr√©cision.png")
print("  17. comparaison_rappel.png")
print("  18. comparaison_f1_score.png")
print("  19. comparaison_roc_auc.png")

print("\nüìà COURBES ROC :")
print("  20. courbes_roc_tous_modeles.png - Toutes les courbes ROC")
print("  21-27. courbe_roc_[nom_modele].png - Courbes ROC individuelles")

print("\nüìâ COURBES PR√âCISION-RAPPEL :")
print("  28. courbes_precision_recall_tous_modeles.png - Toutes les courbes PR")
print("  29-35. courbe_pr_[nom_modele].png - Courbes PR individuelles")

print("\nüíæ FICHIERS DU MOD√àLE :")
print("  ‚Ä¢ meilleur_modele_fraud_detection.pkl - Meilleur mod√®le entra√Æn√©")
print("  ‚Ä¢ scaler.pkl - Scaler pour la normalisation")
print("  ‚Ä¢ train_stats.pkl - Statistiques d'entra√Ænement pour pr√©dictions")

print("\nüìã R√âSUM√â DES M√âTRIQUES :")
print("  ‚úì Accuracy    : Pr√©cision globale du mod√®le")
print("  ‚úì Pr√©cision   : Taux de vrais positifs parmi les pr√©dictions positives")
print("  ‚úì Rappel      : Taux de fraudes d√©tect√©es (sensibilit√©)")
print("  ‚úì F1-Score    : Moyenne harmonique entre pr√©cision et rappel")
print("  ‚úì ROC-AUC     : Aire sous la courbe ROC (capacit√© de discrimination)")
print("  ‚úì Avg Prec    : Average Precision (qualit√© de la courbe PR)")

print("\nüí° INTERPR√âTATION :")
print("  ‚Üí Pour la d√©tection de fraude, privil√©gier:")
print("     ‚Ä¢ F1-Score √©lev√© (√©quilibre pr√©cision/rappel)")
print("     ‚Ä¢ Rappel √©lev√© (d√©tecter un maximum de fraudes)")
print("     ‚Ä¢ ROC-AUC √©lev√© (bonne s√©paration fraude/non-fraude)")
print("\nUtilisation du mod√®le sauvegard√© :")
print("  model = joblib.load('meilleur_modele_fraud_detection.pkl')")
print("  scaler = joblib.load('scaler.pkl')")
print("  train_stats = joblib.load('train_stats.pkl')")
print("  # Voir le script 'prediction_script.py' pour des exemples complets")