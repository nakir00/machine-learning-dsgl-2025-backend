{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUI23UvyPfmI",
        "outputId": "227da36a-375b-4c1c-bfb5-136577925a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "DÉTECTION DE FRAUDE BANCAIRE - MACHINE LEARNING\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    precision_recall_curve,\n",
        "    average_precision_score,\n",
        ")\n",
        "import warnings\n",
        "# Pour la gestion du déséquilibre\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.combine import SMOTETomek\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "import joblib\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"DÉTECTION DE FRAUDE BANCAIRE - MACHINE LEARNING\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K69cHGuKQDsc",
        "outputId": "6fa15963-2433-4d5c-b1d8-5cb63505513c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " question 1: Chargement des données...\n",
            "✓ Données chargées avec succès : 2266 lignes, 14 colonnes\n",
            "\n",
            "Aperçu des données :\n",
            "   Gender  Age  HouseTypeID  ContactAvaliabilityID  HomeCountry  AccountNo  \\\n",
            "0       0   56            1                      0            1    1109976   \n",
            "1       0   56            1                      0            1    1109976   \n",
            "2       0   56            1                      0            1    1109976   \n",
            "3       0   56            1                      0            1    1109976   \n",
            "4       0   56            1                      0            1    1109976   \n",
            "\n",
            "   CardExpiryDate  TransactionAmount  TransactionCountry  LargePurchase  \\\n",
            "0            1811             0.0062                   1              0   \n",
            "1            1811             0.0062                   1              0   \n",
            "2            1811             0.0062                   1              0   \n",
            "3            1811             0.0062                   1              0   \n",
            "4            1811             1.0354                   1              0   \n",
            "\n",
            "   ProductID       CIF  TransactionCurrencyCode  PotentialFraud  \n",
            "0          3  11020290                        1               0  \n",
            "1          3  11020290                        1               0  \n",
            "2          3  11020290                        1               0  \n",
            "3          3  11020290                        1               0  \n",
            "4          3  11020290                        1               0  \n",
            "\n",
            "Informations sur les données :\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2266 entries, 0 to 2265\n",
            "Data columns (total 14 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   Gender                   2266 non-null   int64  \n",
            " 1   Age                      2266 non-null   int64  \n",
            " 2   HouseTypeID              2266 non-null   int64  \n",
            " 3   ContactAvaliabilityID    2266 non-null   int64  \n",
            " 4   HomeCountry              2266 non-null   int64  \n",
            " 5   AccountNo                2266 non-null   int64  \n",
            " 6   CardExpiryDate           2266 non-null   int64  \n",
            " 7   TransactionAmount        2266 non-null   float64\n",
            " 8   TransactionCountry       2266 non-null   int64  \n",
            " 9   LargePurchase            2266 non-null   int64  \n",
            " 10  ProductID                2266 non-null   int64  \n",
            " 11  CIF                      2266 non-null   int64  \n",
            " 12  TransactionCurrencyCode  2266 non-null   int64  \n",
            " 13  PotentialFraud           2266 non-null   int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 248.0 KB\n",
            "None\n",
            "\n",
            "Statistiques descriptives :\n",
            "           Gender          Age  HouseTypeID  ContactAvaliabilityID  \\\n",
            "count  2266.00000  2266.000000  2266.000000            2266.000000   \n",
            "mean      0.30053    32.703883     0.471756               1.049426   \n",
            "std       0.45859    18.020767     0.499312               0.856211   \n",
            "min       0.00000     2.000000     0.000000               0.000000   \n",
            "25%       0.00000    17.000000     0.000000               0.000000   \n",
            "50%       0.00000    33.000000     0.000000               1.000000   \n",
            "75%       1.00000    50.000000     1.000000               2.000000   \n",
            "max       1.00000    63.000000     1.000000               2.000000   \n",
            "\n",
            "       HomeCountry     AccountNo  CardExpiryDate  TransactionAmount  \\\n",
            "count       2266.0  2.266000e+03     2266.000000        2266.000000   \n",
            "mean           1.0  7.430469e+06     2073.290380          45.039090   \n",
            "std            0.0  1.308356e+06       63.267542          90.811319   \n",
            "min            1.0  1.109976e+06     1706.000000           0.000000   \n",
            "25%            1.0  7.627307e+06     2101.000000           1.526750   \n",
            "50%            1.0  7.698046e+06     2102.000000          10.772500   \n",
            "75%            1.0  7.805829e+06     2105.000000          37.200000   \n",
            "max            1.0  7.995399e+06     2109.000000         976.500000   \n",
            "\n",
            "       TransactionCountry  LargePurchase    ProductID           CIF  \\\n",
            "count              2266.0    2266.000000  2266.000000  2.266000e+03   \n",
            "mean                  1.0       0.003089     2.711827  1.113007e+07   \n",
            "std                   0.0       0.055506     0.486835  2.567096e+05   \n",
            "min                   1.0       0.000000     1.000000  1.023500e+07   \n",
            "25%                   1.0       0.000000     2.000000  1.113235e+07   \n",
            "50%                   1.0       0.000000     3.000000  1.124670e+07   \n",
            "75%                   1.0       0.000000     3.000000  1.126767e+07   \n",
            "max                   1.0       1.000000     3.000000  1.132926e+07   \n",
            "\n",
            "       TransactionCurrencyCode  PotentialFraud  \n",
            "count                   2266.0     2266.000000  \n",
            "mean                       1.0        0.111650  \n",
            "std                        0.0        0.315005  \n",
            "min                        1.0        0.000000  \n",
            "25%                        1.0        0.000000  \n",
            "50%                        1.0        0.000000  \n",
            "75%                        1.0        0.000000  \n",
            "max                        1.0        1.000000  \n"
          ]
        }
      ],
      "source": [
        "print(\"\\n question 1: Chargement des données...\")\n",
        "\n",
        "df = pd.read_csv('static/data/creditcarddata.csv')\n",
        "print(f\"✓ Données chargées avec succès : {df.shape[0]} lignes, {df.shape[1]} colonnes\")\n",
        "print(\"\\nAperçu des données :\")\n",
        "print(df.head())\n",
        "print(\"\\nInformations sur les données :\")\n",
        "print(df.info())\n",
        "print(\"\\nStatistiques descriptives :\")\n",
        "print(df.describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhPWHWenQIBa",
        "outputId": "9d8c858a-9a8f-4eb6-f12a-7a2ef0dd355a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "questions 2 : Modèles de classification pour la détection de fraude\n",
            "================================================================================\n",
            "  1. Régression Logistique (Logistic Regression)\n",
            "  2. Arbre de Décision (Decision Tree)\n",
            "  3. Forêt Aléatoire (Random Forest)\n",
            "  4. Gradient Boosting\n",
            "  5. Support Vector Machine (SVM)\n",
            "  6. K-Nearest Neighbors (KNN)\n",
            "  7. Naive Bayes\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"questions 2 : Modèles de classification pour la détection de fraude\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "modeles_liste = [\n",
        "    \"1. Régression Logistique (Logistic Regression)\",\n",
        "    \"2. Arbre de Décision (Decision Tree)\",\n",
        "    \"3. Forêt Aléatoire (Random Forest)\",\n",
        "    \"4. Gradient Boosting\",\n",
        "    \"5. Support Vector Machine (SVM)\",\n",
        "    \"6. K-Nearest Neighbors (KNN)\",\n",
        "    \"7. Naive Bayes\"\n",
        "]\n",
        "\n",
        "for modele in modeles_liste:\n",
        "    print(f\"  {modele}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bTnSlMdlQduf",
        "outputId": "965192fe-9ff0-4485-8776-27ab59fcee32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "[TÂCHE 3] Préparation des données\n",
            "================================================================================\n",
            "\n",
            "3.1 Vérification des valeurs manquantes :\n",
            "Gender                     0\n",
            "Age                        0\n",
            "HouseTypeID                0\n",
            "ContactAvaliabilityID      0\n",
            "HomeCountry                0\n",
            "AccountNo                  0\n",
            "CardExpiryDate             0\n",
            "TransactionAmount          0\n",
            "TransactionCountry         0\n",
            "LargePurchase              0\n",
            "ProductID                  0\n",
            "CIF                        0\n",
            "TransactionCurrencyCode    0\n",
            "PotentialFraud             0\n",
            "dtype: int64\n",
            "✓ Aucune valeur manquante détectée\n",
            "\n",
            "3.2 Vérification des doublons :\n",
            "Nombre de doublons : 933\n",
            "⚠ Doublons détectés. Suppression en cours...\n",
            "✓ Doublons supprimés. Nouvelles dimensions : (1333, 14)\n",
            "\n",
            "3.3 Vérification et traitement des valeurs aberrantes :\n",
            "Colonnes numériques analysées : ['Gender', 'Age', 'HouseTypeID', 'ContactAvaliabilityID', 'HomeCountry', 'AccountNo', 'CardExpiryDate', 'TransactionAmount', 'TransactionCountry', 'LargePurchase', 'ProductID', 'CIF', 'TransactionCurrencyCode']\n",
            "\n",
            "Analyse détaillée des valeurs aberrantes :\n",
            "\n",
            "  Gender :\n",
            "    - Nombre d'outliers (IQR) : 0 (0.00%)\n",
            "    - Limites : [-1.50, 2.50]\n",
            "    - Min: 0.00, Max: 1.00\n",
            "\n",
            "  Age :\n",
            "    - Nombre d'outliers (IQR) : 0 (0.00%)\n",
            "    - Limites : [-32.50, 99.50]\n",
            "    - Min: 2.00, Max: 63.00\n",
            "\n",
            "  HouseTypeID :\n",
            "    - Nombre d'outliers (IQR) : 0 (0.00%)\n",
            "    - Limites : [-1.50, 2.50]\n",
            "    - Min: 0.00, Max: 1.00\n",
            "\n",
            "  ContactAvaliabilityID :\n",
            "    - Nombre d'outliers (IQR) : 0 (0.00%)\n",
            "    - Limites : [-3.00, 5.00]\n",
            "    - Min: 0.00, Max: 2.00\n",
            "\n",
            "  HomeCountry :\n",
            "    - Nombre d'outliers (IQR) : 0 (0.00%)\n",
            "    - Limites : [1.00, 1.00]\n",
            "    - Min: 1.00, Max: 1.00\n",
            "\n",
            "  AccountNo :\n",
            "    - Nombre d'outliers (IQR) : 96 (7.20%)\n",
            "    - Limites : [7359335.00, 8073927.00]\n",
            "    - Min: 1109976.00, Max: 7995399.00\n",
            "\n",
            "  CardExpiryDate :\n",
            "    - Nombre d'outliers (IQR) : 323 (24.23%)\n",
            "    - Limites : [2095.00, 2111.00]\n",
            "    - Min: 1706.00, Max: 2109.00\n",
            "\n",
            "  TransactionAmount :\n",
            "    - Nombre d'outliers (IQR) : 178 (13.35%)\n",
            "    - Limites : [-56.51, 97.64]\n",
            "    - Min: 0.00, Max: 976.50\n",
            "\n",
            "  TransactionCountry :\n",
            "    - Nombre d'outliers (IQR) : 0 (0.00%)\n",
            "    - Limites : [1.00, 1.00]\n",
            "    - Min: 1.00, Max: 1.00\n",
            "\n",
            "  LargePurchase :\n",
            "    - Nombre d'outliers (IQR) : 3 (0.23%)\n",
            "    - Limites : [0.00, 0.00]\n",
            "    - Min: 0.00, Max: 1.00\n",
            "\n",
            "  ProductID :\n",
            "    - Nombre d'outliers (IQR) : 0 (0.00%)\n",
            "    - Limites : [0.50, 4.50]\n",
            "    - Min: 1.00, Max: 3.00\n",
            "\n",
            "  CIF :\n",
            "    - Nombre d'outliers (IQR) : 214 (16.05%)\n",
            "    - Limites : [10915369.00, 11479057.00]\n",
            "    - Min: 10235005.00, Max: 11329257.00\n",
            "\n",
            "  TransactionCurrencyCode :\n",
            "    - Nombre d'outliers (IQR) : 0 (0.00%)\n",
            "    - Limites : [1.00, 1.00]\n",
            "    - Min: 1.00, Max: 1.00\n",
            "\n",
            "⚠ Traitement des outliers pour TransactionAmount :\n",
            "  → Création de features enrichies au lieu de supprimer les outliers\n",
            "  ✓ Feature 'TransactionAmount_is_high' créée (seuil: 372.00)\n",
            "    Transactions élevées détectées : 13\n",
            "  ✓ Feature 'TransactionAmount_zscore' créée\n",
            "    Z-score min: -0.52, max: 10.93\n",
            "  ✓ Feature 'TransactionAmount_log' créée (log1p transformation)\n",
            "  ✓ Feature 'TransactionAmount_category' créée (5 catégories)\n",
            "\n",
            "  Vérification de l'âge :\n",
            "  ✓ Tous les âges sont valides (0-120 ans)\n",
            "✓ Graphique sauvegardé : 03_distribution_originale.png\n",
            "✓ Graphique sauvegardé : 04_distribution_log.png\n",
            "✓ Graphique sauvegardé : 05_distribution_zscore.png\n",
            "\n",
            "✓ Traitement des valeurs aberrantes terminé\n",
            "  Dimensions finales : (1333, 18)\n",
            "\n",
            "3.4 Analyse du déséquilibre de classes :\n",
            "PotentialFraud\n",
            "0    1185\n",
            "1     148\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Proportion de fraudes : 11.10%\n",
            "Proportion de non-fraudes : 88.90%\n",
            "✓ Graphique sauvegardé : 01_distribution_classes_barplot.png\n",
            "✓ Graphique sauvegardé : 02_distribution_classes_piechart.png\n",
            "\n",
            "⚠ Déséquilibre important détecté. Application de SMOTE recommandée.\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[TÂCHE 3] Préparation des données\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 3.1 Vérification des valeurs manquantes\n",
        "print(\"\\n3.1 Vérification des valeurs manquantes :\")\n",
        "valeurs_manquantes = df.isnull().sum()\n",
        "print(valeurs_manquantes)\n",
        "if valeurs_manquantes.sum() > 0:\n",
        "    print(\"⚠ Valeurs manquantes détectées. Traitement en cours...\")\n",
        "    df = df.dropna()\n",
        "    print(f\"✓ Valeurs manquantes supprimées. Nouvelles dimensions : {df.shape}\")\n",
        "else:\n",
        "    print(\"✓ Aucune valeur manquante détectée\")\n",
        "\n",
        "# 3.2 Vérification des doublons\n",
        "print(\"\\n3.2 Vérification des doublons :\")\n",
        "nb_doublons = df.duplicated().sum()\n",
        "print(f\"Nombre de doublons : {nb_doublons}\")\n",
        "if nb_doublons > 0:\n",
        "    print(\"⚠ Doublons détectés. Suppression en cours...\")\n",
        "    df = df.drop_duplicates()\n",
        "    print(f\"✓ Doublons supprimés. Nouvelles dimensions : {df.shape}\")\n",
        "else:\n",
        "    print(\"✓ Aucun doublon détecté\")\n",
        "\n",
        "# 3.3 Vérification et traitement des valeurs aberrantes (outliers)\n",
        "print(\"\\n3.3 Vérification et traitement des valeurs aberrantes :\")\n",
        "colonnes_numeriques = df.select_dtypes(include=[np.number]).columns.drop('PotentialFraud')\n",
        "print(f\"Colonnes numériques analysées : {list(colonnes_numeriques)}\")\n",
        "\n",
        "# Fonction pour détecter les outliers avec IQR\n",
        "def detect_outliers_iqr(data, column):\n",
        "    Q1 = data[column].quantile(0.25)\n",
        "    Q3 = data[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = (data[column] < lower_bound) | (data[column] > upper_bound)\n",
        "    return outliers, lower_bound, upper_bound\n",
        "\n",
        "# Fonction pour calculer le Z-score\n",
        "def calculate_zscore(data, column):\n",
        "    mean = data[column].mean()\n",
        "    std = data[column].std()\n",
        "    zscore = (data[column] - mean) / std\n",
        "    return zscore\n",
        "\n",
        "# Analyse des outliers pour chaque colonne numérique\n",
        "print(\"\\nAnalyse détaillée des valeurs aberrantes :\")\n",
        "outliers_info = {}\n",
        "\n",
        "for col in colonnes_numeriques:\n",
        "    outliers_mask, lower, upper = detect_outliers_iqr(df, col)\n",
        "    nb_outliers = outliers_mask.sum()\n",
        "    pct_outliers = (nb_outliers / len(df)) * 100\n",
        "    \n",
        "    print(f\"\\n  {col} :\")\n",
        "    print(f\"    - Nombre d'outliers (IQR) : {nb_outliers} ({pct_outliers:.2f}%)\")\n",
        "    print(f\"    - Limites : [{lower:.2f}, {upper:.2f}]\")\n",
        "    print(f\"    - Min: {df[col].min():.2f}, Max: {df[col].max():.2f}\")\n",
        "    \n",
        "    outliers_info[col] = {\n",
        "        'count': nb_outliers,\n",
        "        'percentage': pct_outliers,\n",
        "        'lower': lower,\n",
        "        'upper': upper\n",
        "    }\n",
        "\n",
        "# Traitement spécifique pour TransactionAmount (approche recommandée)\n",
        "print(\"\\n⚠ Traitement des outliers pour TransactionAmount :\")\n",
        "print(\"  → Création de features enrichies au lieu de supprimer les outliers\")\n",
        "\n",
        "# 1. Créer un indicateur de transaction élevée (> 99e percentile)\n",
        "percentile_99 = df['TransactionAmount'].quantile(0.99)\n",
        "df['TransactionAmount_is_high'] = (df['TransactionAmount'] > percentile_99).astype(int)\n",
        "print(f\"  ✓ Feature 'TransactionAmount_is_high' créée (seuil: {percentile_99:.2f})\")\n",
        "print(f\"    Transactions élevées détectées : {df['TransactionAmount_is_high'].sum()}\")\n",
        "\n",
        "# 2. Calculer le Z-score comme feature\n",
        "df['TransactionAmount_zscore'] = calculate_zscore(df, 'TransactionAmount')\n",
        "print(f\"  ✓ Feature 'TransactionAmount_zscore' créée\")\n",
        "print(f\"    Z-score min: {df['TransactionAmount_zscore'].min():.2f}, max: {df['TransactionAmount_zscore'].max():.2f}\")\n",
        "\n",
        "# 3. Transformation logarithmique pour réduire l'asymétrie\n",
        "df['TransactionAmount_log'] = np.log1p(df['TransactionAmount'])\n",
        "print(f\"  ✓ Feature 'TransactionAmount_log' créée (log1p transformation)\")\n",
        "\n",
        "# 4. Créer des catégories de montant\n",
        "bins = [0, 10, 50, 100, 500, np.inf]\n",
        "labels = ['Très faible', 'Faible', 'Moyen', 'Élevé', 'Très élevé']\n",
        "df['TransactionAmount_category'] = pd.cut(df['TransactionAmount'], bins=bins, labels=labels)\n",
        "df['TransactionAmount_category'] = df['TransactionAmount_category'].cat.codes\n",
        "print(f\"  ✓ Feature 'TransactionAmount_category' créée (5 catégories)\")\n",
        "\n",
        "# Vérification des valeurs impossibles pour Age\n",
        "print(\"\\n  Vérification de l'âge :\")\n",
        "age_invalid = ((df['Age'] < 0) | (df['Age'] > 120)).sum()\n",
        "if age_invalid > 0:\n",
        "    print(f\"  ⚠ {age_invalid} âges invalides détectés. Correction en cours...\")\n",
        "    df = df[(df['Age'] >= 0) & (df['Age'] <= 120)]\n",
        "    print(f\"  ✓ Âges invalides supprimés\")\n",
        "else:\n",
        "    print(f\"  ✓ Tous les âges sont valides (0-120 ans)\")\n",
        "\n",
        "# Visualisation de l'impact de la transformation logarithmique\n",
        "\n",
        "# Graphique 1 : Distribution originale\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df['TransactionAmount'], bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
        "plt.title('Distribution originale de TransactionAmount', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Montant', fontsize=12)\n",
        "plt.ylabel('Fréquence', fontsize=12)\n",
        "plt.axvline(percentile_99, color='red', linestyle='--', linewidth=2, label=f'99e percentile ({percentile_99:.2f})')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('03_distribution_originale.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"✓ Graphique sauvegardé : 03_distribution_originale.png\")\n",
        "\n",
        "# Graphique 2 : Distribution log-transformée\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df['TransactionAmount_log'], bins=50, color='green', edgecolor='black', alpha=0.7)\n",
        "plt.title('Distribution log-transformée de TransactionAmount', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('log(Montant + 1)', fontsize=12)\n",
        "plt.ylabel('Fréquence', fontsize=12)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('04_distribution_log.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"✓ Graphique sauvegardé : 04_distribution_log.png\")\n",
        "\n",
        "# Graphique 3 : Distribution des Z-scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df['TransactionAmount_zscore'], bins=50, color='orange', edgecolor='black', alpha=0.7)\n",
        "plt.title('Distribution des Z-scores de TransactionAmount', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Z-score', fontsize=12)\n",
        "plt.ylabel('Fréquence', fontsize=12)\n",
        "plt.axvline(-3, color='red', linestyle='--', linewidth=2, label='Seuil -3')\n",
        "plt.axvline(3, color='red', linestyle='--', linewidth=2, label='Seuil +3')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('05_distribution_zscore.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"✓ Graphique sauvegardé : 05_distribution_zscore.png\")\n",
        "\n",
        "print(\"\\n✓ Traitement des valeurs aberrantes terminé\")\n",
        "print(f\"  Dimensions finales : {df.shape}\")\n",
        "\n",
        "# 3.4 Analyse du déséquilibre de classes\n",
        "print(\"\\n3.4 Analyse du déséquilibre de classes :\")\n",
        "distribution_classe = df['PotentialFraud'].value_counts()\n",
        "print(distribution_classe)\n",
        "print(f\"\\nProportion de fraudes : {distribution_classe[1]/len(df)*100:.2f}%\")\n",
        "print(f\"Proportion de non-fraudes : {distribution_classe[0]/len(df)*100:.2f}%\")\n",
        "\n",
        "# Visualisation du déséquilibre - Graphique 1 : Bar plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "distribution_classe.plot(kind='bar', color=['green', 'red'])\n",
        "plt.title('Distribution des classes', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('PotentialFraud', fontsize=12)\n",
        "plt.ylabel('Nombre d\\'observations', fontsize=12)\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('01_distribution_classes_barplot.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"✓ Graphique sauvegardé : 01_distribution_classes_barplot.png\")\n",
        "\n",
        "# Visualisation du déséquilibre - Graphique 2 : Pie chart\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(distribution_classe, labels=['Non-Fraude', 'Fraude'], autopct='%1.1f%%', \n",
        "        colors=['green', 'red'], startangle=90, textprops={'fontsize': 12})\n",
        "plt.title('Proportion des classes', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig('02_distribution_classes_piechart.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"✓ Graphique sauvegardé : 02_distribution_classes_piechart.png\")\n",
        "\n",
        "# Gestion du déséquilibre si nécessaire\n",
        "if distribution_classe[1] / distribution_classe[0] < 0.3:\n",
        "    print(\"\\n⚠ Déséquilibre important détecté. Application de SMOTE recommandée.\")\n",
        "    desequilibre = True\n",
        "else:\n",
        "    desequilibre = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCgTJkMzQm4A",
        "outputId": "81f2274f-2638-4f36-f86b-996ef523de71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            " question 4 : Division des données\n",
            "================================================================================\n",
            "  Données d'entraînement : 933 observations (70%)\n",
            "  Données de test : 400 observations (30%)\n",
            "\n",
            "Distribution dans le train :\n",
            "PotentialFraud\n",
            "0    829\n",
            "1    104\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribution dans le test :\n",
            "PotentialFraud\n",
            "0    356\n",
            "1     44\n",
            "Name: count, dtype: int64\n",
            "\n",
            "  Application de SMOTE pour équilibrer les classes...\n",
            "  Après SMOTE - Train : 1658 observations\n",
            "Distribution après SMOTE :\n",
            "PotentialFraud\n",
            "0    829\n",
            "1    829\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\" question 4 : Division des données\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "X = df.drop('PotentialFraud', axis=1)\n",
        "y = df['PotentialFraud']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"  Données d'entraînement : {X_train.shape[0]} observations ({70}%)\")\n",
        "print(f\"  Données de test : {X_test.shape[0]} observations ({30}%)\")\n",
        "print(f\"\\nDistribution dans le train :\")\n",
        "print(y_train.value_counts())\n",
        "print(f\"\\nDistribution dans le test :\")\n",
        "print(y_test.value_counts())\n",
        "\n",
        "\n",
        "if desequilibre:\n",
        "    print(\"\\n  Application de SMOTE pour équilibrer les classes...\")\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "    print(f\"  Après SMOTE - Train : {X_train.shape[0]} observations\")\n",
        "    print(f\"Distribution après SMOTE :\")\n",
        "    print(y_train.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "NORMALISATION DES DONNÉES\n",
            "================================================================================\n",
            "\n",
            "Plusieurs méthodes de normalisation disponibles :\n",
            "  1. StandardScaler : (X - mean) / std → Distribution N(0,1)\n",
            "  2. MinMaxScaler : (X - min) / (max - min) → Échelle [0,1]\n",
            "  3. RobustScaler : Utilise la médiane et IQR → Robuste aux outliers\n",
            "\n",
            "Statistiques AVANT normalisation (échantillon) :\n",
            "               Age  TransactionAmount\n",
            "count  1658.000000        1658.000000\n",
            "mean     33.142340          33.849354\n",
            "std      17.035205          69.726600\n",
            "min       2.000000           0.000000\n",
            "25%      19.000000           0.000000\n",
            "50%      33.000000           7.241600\n",
            "75%      48.000000          29.195538\n",
            "max      63.000000         976.500000\n",
            "\n",
            "→ Application de StandardScaler (méthode principale)\n",
            "  ✓ StandardScaler appliqué\n",
            "\n",
            "→ Application de RobustScaler (robuste aux outliers)\n",
            "  ✓ RobustScaler appliqué\n",
            "\n",
            "→ Application de MinMaxScaler (échelle 0-1)\n",
            "  ✓ MinMaxScaler appliqué\n",
            "\n",
            "✓ Normalisation principale : StandardScaler sélectionné\n",
            "\n",
            "Statistiques APRÈS normalisation (échantillon) :\n",
            "               Age  TransactionAmount\n",
            "count  1658.000000        1658.000000\n",
            "mean      0.510530           0.034664\n",
            "std       0.279266           0.071405\n",
            "min       0.000000           0.000000\n",
            "25%       0.278689           0.000000\n",
            "50%       0.508197           0.007416\n",
            "75%       0.754098           0.029898\n",
            "max       1.000000           1.000000\n",
            "  Graphique sauvegardé : 06_normalisation_avant_Age.png\n",
            "  Graphique sauvegardé : 07_normalisation_apres_Age.png\n",
            "  Graphique sauvegardé : 06_normalisation_avant_TransactionAmount.png\n",
            "  Graphique sauvegardé : 07_normalisation_apres_TransactionAmount.png\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"NORMALISATION DES DONNÉES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nPlusieurs méthodes de normalisation disponibles :\")\n",
        "print(\"  1. StandardScaler : (X - mean) / std → Distribution N(0,1)\")\n",
        "print(\"  2. MinMaxScaler : (X - min) / (max - min) → Échelle [0,1]\")\n",
        "print(\"  3. RobustScaler : Utilise la médiane et IQR → Robuste aux outliers\")\n",
        "\n",
        "print(\"\\nStatistiques AVANT normalisation (échantillon) :\")\n",
        "print(X_train[['Age', 'TransactionAmount']].describe())\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "\n",
        "print(\"\\n→ Application de StandardScaler (méthode principale)\")\n",
        "scaler_standard = StandardScaler()\n",
        "X_train_standard = scaler_standard.fit_transform(X_train)\n",
        "X_test_standard = scaler_standard.transform(X_test)\n",
        "print(\"  ✓ StandardScaler appliqué\")\n",
        "\n",
        "print(\"\\n→ Application de RobustScaler (robuste aux outliers)\")\n",
        "scaler_robust = RobustScaler()\n",
        "X_train_robust = scaler_robust.fit_transform(X_train)\n",
        "X_test_robust = scaler_robust.transform(X_test)\n",
        "print(\"  ✓ RobustScaler appliqué\")\n",
        "\n",
        "print(\"\\n→ Application de MinMaxScaler (échelle 0-1)\")\n",
        "scaler_minmax = MinMaxScaler()\n",
        "X_train_minmax = scaler_minmax.fit_transform(X_train)\n",
        "X_test_minmax = scaler_minmax.transform(X_test)\n",
        "print(\"  ✓ MinMaxScaler appliqué\")\n",
        "\n",
        "X_train_scaled = X_train_minmax\n",
        "X_test_scaled = X_test_minmax\n",
        "scaler = scaler_minmax\n",
        "\n",
        "print(\"\\n✓ Normalisation principale : StandardScaler sélectionné\")\n",
        "\n",
        "X_train_scaled_df = pd.DataFrame(\n",
        "    X_train_scaled, \n",
        "    columns=X_train.columns\n",
        ")\n",
        "print(\"\\nStatistiques APRÈS normalisation (échantillon) :\")\n",
        "print(X_train_scaled_df[['Age', 'TransactionAmount']].describe())\n",
        "\n",
        "colonnes_viz = ['Age', 'TransactionAmount']\n",
        "\n",
        "for idx, col in enumerate(colonnes_viz):\n",
        "    # Graphique AVANT normalisation\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(X_train[col], bins=30, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "    plt.title(f'{col} - AVANT normalisation', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Valeur', fontsize=12)\n",
        "    plt.ylabel('Fréquence', fontsize=12)\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'static/images/normalisation/avant/{col}.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"  Graphique sauvegardé : 06_normalisation_avant_{col}.png\")\n",
        "    \n",
        "    # Graphique APRÈS normalisation\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    col_index = list(X_train.columns).index(col)\n",
        "    plt.hist(X_train_scaled[:, col_index], bins=30, color='green', alpha=0.7, edgecolor='black')\n",
        "    plt.title(f'{col} - APRÈS normalisation (StandardScaler)', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Valeur normalisée', fontsize=12)\n",
        "    plt.ylabel('Fréquence', fontsize=12)\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'static/images/normalisation/apres/{col}.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"  Graphique sauvegardé : 07_normalisation_apres_{col}.png\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXza5cQXZdCF",
        "outputId": "94d639db-e2fc-4f37-cee1-8a88cd2732d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "question 5 : Entraînement des modèles\n",
            "================================================================================\n",
            "\n",
            "  Entraînement de Logistic Regression...\n",
            "    Logistic Regression entraîné avec succès\n",
            "\n",
            "  Entraînement de Decision Tree...\n",
            "    Decision Tree entraîné avec succès\n",
            "\n",
            "  Entraînement de Random Forest...\n",
            "    Random Forest entraîné avec succès\n",
            "\n",
            "  Entraînement de Gradient Boosting...\n",
            "    Gradient Boosting entraîné avec succès\n",
            "\n",
            "  Entraînement de SVM...\n",
            "    SVM entraîné avec succès\n",
            "\n",
            "  Entraînement de KNN...\n",
            "    KNN entraîné avec succès\n",
            "\n",
            "  Entraînement de Naive Bayes...\n",
            "    Naive Bayes entraîné avec succès\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"question 5 : Entraînement des modèles\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "modeles = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42, n_estimators=100),\n",
        "    'SVM': SVC(random_state=42, kernel='rbf'),\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "    'Naive Bayes': GaussianNB()\n",
        "}\n",
        "\n",
        "modeles_entraines = {}\n",
        "for nom, modele in modeles.items():\n",
        "    print(f\"\\n  Entraînement de {nom}...\")\n",
        "    modele.fit(X_train_scaled, y_train)\n",
        "    modeles_entraines[nom] = modele\n",
        "    print(f\"    {nom} entraîné avec succès\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g3CVjtXQZlHx",
        "outputId": "15077071-0268-4c0d-e758-057d31112d1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "question 6 : Évaluation des modèles - Matrices de confusion\n",
            "================================================================================\n",
            " Matrice de confusion sauvegardée : static/images/matrice_confusion/Logistic_Regression.png\n",
            "   TN=248, FP=108, FN=18, TP=26\n",
            " Matrice de confusion sauvegardée : static/images/matrice_confusion/Decision_Tree.png\n",
            "   TN=283, FP=73, FN=33, TP=11\n",
            " Matrice de confusion sauvegardée : static/images/matrice_confusion/Random_Forest.png\n",
            "   TN=301, FP=55, FN=32, TP=12\n",
            " Matrice de confusion sauvegardée : static/images/matrice_confusion/Gradient_Boosting.png\n",
            "   TN=285, FP=71, FN=21, TP=23\n",
            " Matrice de confusion sauvegardée : static/images/matrice_confusion/SVM.png\n",
            "   TN=248, FP=108, FN=18, TP=26\n",
            " Matrice de confusion sauvegardée : static/images/matrice_confusion/KNN.png\n",
            "   TN=265, FP=91, FN=24, TP=20\n",
            " Matrice de confusion sauvegardée : static/images/matrice_confusion/Naive_Bayes.png\n",
            "   TN=112, FP=244, FN=1, TP=43\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"question 6 : Évaluation des modèles - Matrices de confusion\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for idx, (nom, modele) in enumerate(modeles_entraines.items()):\n",
        "    y_pred = modele.predict(X_test_scaled)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "                xticklabels=['Non-Fraude', 'Fraude'],\n",
        "                yticklabels=['Non-Fraude', 'Fraude'],\n",
        "                cbar_kws={'label': 'Nombre de prédictions'})\n",
        "    plt.title(f'Matrice de confusion - {nom}', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Vraie classe', fontsize=12)\n",
        "    plt.xlabel('Classe prédite', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    nom_fichier = f'static/images/matrice_confusion/{nom.replace(\" \", \"_\")}.png'\n",
        "    plt.savefig(nom_fichier, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\" Matrice de confusion sauvegardée : {nom_fichier}\")\n",
        "    \n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    print(f\"   TN={tn}, FP={fp}, FN={fn}, TP={tp}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvQERmMoZpva",
        "outputId": "072b7998-de45-4959-8633-b85e9fa28b19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "question 7 : Calcul des métriques de performance\n",
            "================================================================================\n",
            "\n",
            "Logistic Regression :\n",
            "  Accuracy        : 0.6850 (68.50%)\n",
            "  Précision       : 0.1940 (19.40%)\n",
            "  Rappel (Recall) : 0.5909 (59.09%)\n",
            "  F1-Score        : 0.2921 (29.21%)\n",
            "  ROC-AUC         : 0.7191\n",
            "  Avg Precision   : 0.2102\n",
            "\n",
            "Decision Tree :\n",
            "  Accuracy        : 0.7350 (73.50%)\n",
            "  Précision       : 0.1310 (13.10%)\n",
            "  Rappel (Recall) : 0.2500 (25.00%)\n",
            "  F1-Score        : 0.1719 (17.19%)\n",
            "  ROC-AUC         : 0.5374\n",
            "  Avg Precision   : 0.1169\n",
            "\n",
            "Random Forest :\n",
            "  Accuracy        : 0.7825 (78.25%)\n",
            "  Précision       : 0.1791 (17.91%)\n",
            "  Rappel (Recall) : 0.2727 (27.27%)\n",
            "  F1-Score        : 0.2162 (21.62%)\n",
            "  ROC-AUC         : 0.6703\n",
            "  Avg Precision   : 0.1715\n",
            "\n",
            "Gradient Boosting :\n",
            "  Accuracy        : 0.7700 (77.00%)\n",
            "  Précision       : 0.2447 (24.47%)\n",
            "  Rappel (Recall) : 0.5227 (52.27%)\n",
            "  F1-Score        : 0.3333 (33.33%)\n",
            "  ROC-AUC         : 0.7484\n",
            "  Avg Precision   : 0.2372\n",
            "\n",
            "SVM :\n",
            "  Accuracy        : 0.6850 (68.50%)\n",
            "  Précision       : 0.1940 (19.40%)\n",
            "  Rappel (Recall) : 0.5909 (59.09%)\n",
            "  F1-Score        : 0.2921 (29.21%)\n",
            "  ROC-AUC         : 0.7135\n",
            "  Avg Precision   : 0.2053\n",
            "\n",
            "KNN :\n",
            "  Accuracy        : 0.7125 (71.25%)\n",
            "  Précision       : 0.1802 (18.02%)\n",
            "  Rappel (Recall) : 0.4545 (45.45%)\n",
            "  F1-Score        : 0.2581 (25.81%)\n",
            "  ROC-AUC         : 0.6726\n",
            "  Avg Precision   : 0.1728\n",
            "\n",
            "Naive Bayes :\n",
            "  Accuracy        : 0.3875 (38.75%)\n",
            "  Précision       : 0.1498 (14.98%)\n",
            "  Rappel (Recall) : 0.9773 (97.73%)\n",
            "  F1-Score        : 0.2598 (25.98%)\n",
            "  ROC-AUC         : 0.7316\n",
            "  Avg Precision   : 0.2232\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"question 7 : Calcul des métriques de performance\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "resultats = []\n",
        "courbes_roc = {}\n",
        "courbes_pr = {}\n",
        "\n",
        "for nom, modele in modeles_entraines.items():\n",
        "    y_pred = modele.predict(X_test_scaled)\n",
        "    \n",
        "    if hasattr(modele, 'predict_proba'):\n",
        "        y_pred_proba = modele.predict_proba(X_test_scaled)[:, 1]\n",
        "    elif hasattr(modele, 'decision_function'):\n",
        "        y_pred_proba = modele.decision_function(X_test_scaled)\n",
        "    else:\n",
        "        y_pred_proba = y_pred  \n",
        "    \n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "    \n",
        "    try:\n",
        "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "        courbes_roc[nom] = (fpr, tpr, roc_auc)\n",
        "    except:\n",
        "        roc_auc = np.nan\n",
        "        courbes_roc[nom] = None\n",
        "    \n",
        "    try:\n",
        "        avg_precision = average_precision_score(y_test, y_pred_proba)\n",
        "        precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba)\n",
        "        courbes_pr[nom] = (recall_curve, precision_curve, avg_precision)\n",
        "    except:\n",
        "        avg_precision = np.nan\n",
        "        courbes_pr[nom] = None\n",
        "    \n",
        "    resultats.append({\n",
        "        'Modèle': nom,\n",
        "        'Accuracy': acc,\n",
        "        'Précision': prec,\n",
        "        'Rappel': rec,\n",
        "        'F1-Score': f1,\n",
        "        'ROC-AUC': roc_auc,\n",
        "        'Avg Precision': avg_precision\n",
        "    })\n",
        "    \n",
        "    print(f\"\\n{nom} :\")\n",
        "    print(f\"  Accuracy        : {acc:.4f} ({acc*100:.2f}%)\")\n",
        "    print(f\"  Précision       : {prec:.4f} ({prec*100:.2f}%)\")\n",
        "    print(f\"  Rappel (Recall) : {rec:.4f} ({rec*100:.2f}%)\")\n",
        "    print(f\"  F1-Score        : {f1:.4f} ({f1*100:.2f}%)\")\n",
        "    print(f\"  ROC-AUC         : {roc_auc:.4f}\" if not np.isnan(roc_auc) else \"  ROC-AUC         : N/A\")\n",
        "    print(f\"  Avg Precision   : {avg_precision:.4f}\" if not np.isnan(avg_precision) else \"  Avg Precision   : N/A\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "id": "a4EikSfJZttT",
        "outputId": "84d0c01a-8b30-4980-a848-6e3a824db7d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "question 8 : Comparaison des modèles\n",
            "================================================================================\n",
            "\n",
            "Tableau comparatif des performances :\n",
            "             Modèle  Accuracy  Précision   Rappel  F1-Score  ROC-AUC  Avg Precision\n",
            "  Gradient Boosting    0.7700   0.244681 0.522727  0.333333 0.748436       0.237187\n",
            "Logistic Regression    0.6850   0.194030 0.590909  0.292135 0.719133       0.210215\n",
            "                SVM    0.6850   0.194030 0.590909  0.292135 0.713451       0.205316\n",
            "        Naive Bayes    0.3875   0.149826 0.977273  0.259819 0.731550       0.223177\n",
            "                KNN    0.7125   0.180180 0.454545  0.258065 0.672625       0.172782\n",
            "      Random Forest    0.7825   0.179104 0.272727  0.216216 0.670263       0.171548\n",
            "      Decision Tree    0.7350   0.130952 0.250000  0.171875 0.537379       0.116878\n",
            "  Graphique sauvegardé : 15_comparaison_accuracy.png\n",
            "  Graphique sauvegardé : 16_comparaison_précision.png\n",
            "  Graphique sauvegardé : 17_comparaison_rappel.png\n",
            "  Graphique sauvegardé : 18_comparaison_f1_score.png\n",
            "  Graphique sauvegardé : 19_comparaison_roc_auc.png\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"question 8 : Comparaison des modèles\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "df_resultats = pd.DataFrame(resultats)\n",
        "df_resultats = df_resultats.sort_values('F1-Score', ascending=False)\n",
        "\n",
        "print(\"\\nTableau comparatif des performances :\")\n",
        "print(df_resultats.to_string(index=False))\n",
        "\n",
        "metriques = ['Accuracy', 'Précision', 'Rappel', 'F1-Score', 'ROC-AUC']\n",
        "numero_base = 15\n",
        "\n",
        "for idx, metrique in enumerate(metriques):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    \n",
        "    df_plot = df_resultats[['Modèle', metrique]].dropna()\n",
        "    df_plot_sorted = df_plot.sort_values(metrique, ascending=True)\n",
        "    \n",
        "    bars = plt.barh(df_plot_sorted['Modèle'], df_plot_sorted[metrique], color='steelblue')\n",
        "    plt.title(f'Comparaison des modèles - {metrique}', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel(metrique, fontsize=12)\n",
        "    plt.ylabel('Modèle', fontsize=12)\n",
        "    plt.xlim([0, 1.1])\n",
        "    plt.grid(axis='x', alpha=0.3)\n",
        "    \n",
        "    for i, (bar, value) in enumerate(zip(bars, df_plot_sorted[metrique])):\n",
        "        plt.text(value + 0.01, i, f'{value:.3f}', va='center', fontsize=10)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    numero = numero_base + idx\n",
        "    plt.savefig(f'static/images/comparaison/{metrique.lower().replace(\"-\", \"_\")}.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"  Graphique sauvegardé : {numero:02d}_comparaison_{metrique.lower().replace('-', '_')}.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "COURBES ROC (Receiver Operating Characteristic)\n",
            "================================================================================\n",
            " Graphique sauvegardé : modeles.png\n",
            "✓ Courbe ROC sauvegardée : roc/Logistic_Regression.png\n",
            "✓ Courbe ROC sauvegardée : roc/Decision_Tree.png\n",
            "✓ Courbe ROC sauvegardée : roc/Random_Forest.png\n",
            "✓ Courbe ROC sauvegardée : roc/Gradient_Boosting.png\n",
            "✓ Courbe ROC sauvegardée : roc/SVM.png\n",
            "✓ Courbe ROC sauvegardée : roc/KNN.png\n",
            "✓ Courbe ROC sauvegardée : roc/Naive_Bayes.png\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COURBES ROC (Receiver Operating Characteristic)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "for nom, data in courbes_roc.items():\n",
        "    if data is not None:\n",
        "        fpr, tpr, roc_auc = data\n",
        "        plt.plot(fpr, tpr, lw=2, label=f'{nom} (AUC = {roc_auc:.3f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Aléatoire (AUC = 0.500)')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Taux de Faux Positifs (FPR)', fontsize=12)\n",
        "plt.ylabel('Taux de Vrais Positifs (TPR)', fontsize=12)\n",
        "plt.title('Courbes ROC - Tous les modèles', fontsize=14, fontweight='bold')\n",
        "plt.legend(loc=\"lower right\", fontsize=9)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('static/images/comparaison/modeles.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\" Graphique sauvegardé : modeles.png\")\n",
        "\n",
        "for nom, data in courbes_roc.items():\n",
        "    if data is not None:\n",
        "        fpr, tpr, roc_auc = data\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC (AUC = {roc_auc:.3f})')\n",
        "        plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Aléatoire (AUC = 0.500)')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('Taux de Faux Positifs (FPR)', fontsize=12)\n",
        "        plt.ylabel('Taux de Vrais Positifs (TPR)', fontsize=12)\n",
        "        plt.title(f'Courbe ROC - {nom}', fontsize=14, fontweight='bold')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'static/images/comparaison/roc/{nom.replace(\" \", \"_\")}.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        print(f\"✓ Courbe ROC sauvegardée : roc/{nom.replace(' ', '_')}.png\")\n",
        "        numero += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "COURBES PRECISION-RECALL\n",
            "================================================================================\n",
            " Courbe PR sauvegardée : precision_recall/Logistic_Regression.png\n",
            " Courbe PR sauvegardée : precision_recall/Decision_Tree.png\n",
            " Courbe PR sauvegardée : precision_recall/Random_Forest.png\n",
            " Courbe PR sauvegardée : precision_recall/Gradient_Boosting.png\n",
            " Courbe PR sauvegardée : precision_recall/SVM.png\n",
            " Courbe PR sauvegardée : precision_recall/KNN.png\n",
            " Courbe PR sauvegardée : precision_recall/Naive_Bayes.png\n",
            "\n",
            "================================================================================\n",
            " MEILLEUR MODÈLE : Gradient Boosting\n",
            "   F1-Score  : 0.3333 (33.33%)\n",
            "   ROC-AUC   : 0.7484\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COURBES PRECISION-RECALL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "for nom, data in courbes_pr.items():\n",
        "    if data is not None:\n",
        "        recall_curve, precision_curve, avg_precision = data\n",
        "        plt.plot(recall_curve, precision_curve, lw=2, \n",
        "                label=f'{nom} (AP = {avg_precision:.3f})')\n",
        "\n",
        "plt.xlabel('Rappel (Recall)', fontsize=12)\n",
        "plt.ylabel('Précision', fontsize=12)\n",
        "plt.title('Courbes Précision-Rappel - Tous les modèles', fontsize=14, fontweight='bold')\n",
        "plt.legend(loc=\"lower left\", fontsize=9)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.tight_layout()\n",
        "plt.savefig('static/images/comparaison/precision_recall_modeles.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "for nom, data in courbes_pr.items():\n",
        "    if data is not None:\n",
        "        recall_curve, precision_curve, avg_precision = data\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(recall_curve, precision_curve, color='blue', lw=2, \n",
        "                label=f'PR (AP = {avg_precision:.3f})')\n",
        "        plt.xlabel('Rappel (Recall)', fontsize=12)\n",
        "        plt.ylabel('Précision', fontsize=12)\n",
        "        plt.title(f'Courbe Précision-Rappel - {nom}', fontsize=14, fontweight='bold')\n",
        "        plt.legend(loc=\"lower left\")\n",
        "        plt.grid(alpha=0.3)\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'static/images/comparaison/precision_recall/{nom.replace(\" \", \"_\")}.png', dpi=300, bbox_inches='tight')\n",
        "        plt.close()\n",
        "        print(f\" Courbe PR sauvegardée : precision_recall/{nom.replace(' ', '_')}.png\")\n",
        "\n",
        "meilleur_modele_nom = df_resultats.iloc[0]['Modèle']\n",
        "meilleur_f1 = df_resultats.iloc[0]['F1-Score']\n",
        "meilleur_roc_auc = df_resultats.iloc[0]['ROC-AUC']\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\" MEILLEUR MODÈLE : {meilleur_modele_nom}\")\n",
        "print(f\"   F1-Score  : {meilleur_f1:.4f} ({meilleur_f1*100:.2f}%)\")\n",
        "print(f\"   ROC-AUC   : {meilleur_roc_auc:.4f}\" if not np.isnan(meilleur_roc_auc) else \"   ROC-AUC   : N/A\")\n",
        "print(f\"{'='*80}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6miTVPGZyV3",
        "outputId": "ac2a5f55-03dc-41ce-9230-6a1ac20426c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "question 9 : Sauvegarde du meilleur modèle\n",
            "================================================================================\n",
            "\n",
            "Utilisation du modèle sauvegardé :\n",
            "  model = joblib.load('ml/model.pkl')\n",
            "  scaler = joblib.load('ml/scaler.pkl')\n",
            "  train_stats = joblib.load('ml/train_stats.pkl')\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"question 9 : Sauvegarde du meilleur modèle\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "meilleur_modele = modeles_entraines[meilleur_modele_nom]\n",
        "\n",
        "joblib.dump(meilleur_modele, 'ml/model.pkl')\n",
        "joblib.dump(scaler, 'ml/scaler.pkl')\n",
        "\n",
        "train_stats = {\n",
        "    'percentile_99': df['TransactionAmount'].quantile(0.99),\n",
        "    'mean': df['TransactionAmount'].mean(),\n",
        "    'std': df['TransactionAmount'].std()\n",
        "}\n",
        "joblib.dump(train_stats, 'ml/train_stats.pkl')\n",
        "\n",
        "modele_charge = joblib.load('ml/model.pkl')\n",
        "\n",
        "print(\"\\nUtilisation du modèle sauvegardé :\")\n",
        "print(\"  model = joblib.load('ml/model.pkl')\")\n",
        "print(\"  scaler = joblib.load('ml/scaler.pkl')\")\n",
        "print(\"  train_stats = joblib.load('ml/train_stats.pkl')\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.9.6)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
