"""
Service de Pr√©diction - D√©tection de fraude avec Machine Learning
"""
from logging import log
import os
import joblib
import numpy as np
import pandas as pd
from pathlib import Path


class PredictionService:
    """Service pour la pr√©diction de fraude avec le mod√®le ML"""
    
    # Chemins par d√©faut des fichiers du mod√®le (chemins ABSOLUS)
    BASE_DIR = Path(__file__).resolve().parent.parent
    DEFAULT_MODEL_PATH = BASE_DIR / 'ml' / 'model.pkl'
    DEFAULT_SCALER_PATH = BASE_DIR / 'ml' / 'scaler.pkl'
    DEFAULT_STATS_PATH = BASE_DIR / 'ml' / 'train_stats.pkl'
    
    # Instance singleton
    _instance = None
    _model = None
    _scaler = None
    _train_stats = None
    _is_loaded = False
    
    def __new__(cls):
        """Singleton pattern pour √©viter de recharger le mod√®le"""
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        """Initialise le service et charge le mod√®le si pas d√©j√† fait"""
        if not PredictionService._is_loaded:
            self.load_model()
    
    @classmethod
    def load_model(cls, model_path=None, scaler_path=None, stats_path=None):
        """
        Charge le mod√®le ML, le scaler et les statistiques d'entra√Ænement
        
        Args:
            model_path (str): Chemin vers le mod√®le .pkl
            scaler_path (str): Chemin vers le scaler .pkl
            stats_path (str): Chemin vers les stats d'entra√Ænement .pkl
            
        Returns:
            bool: True si chargement r√©ussi, False sinon
        """
        # Utiliser des chemins absolus
        if model_path:
            model_path = Path(model_path)
            print(model_path)
        else:
            model_path = Path(os.environ.get('MODEL_PATH', cls.DEFAULT_MODEL_PATH))
        
        if scaler_path:
            scaler_path = Path(scaler_path)
            print(scaler_path)
        else:
            scaler_path = Path(os.environ.get('SCALER_PATH', cls.DEFAULT_SCALER_PATH))
        
        if stats_path:
            stats_path = Path(stats_path)
            print(stats_path)
        else:
            stats_path = Path(os.environ.get('STATS_PATH', cls.DEFAULT_STATS_PATH))
        
        print(f"üîç Tentative de chargement depuis:")
        print(f"   üìÅ Dossier de travail: {os.getcwd()}")
        print(f"   üìÑ Mod√®le: {model_path.absolute()}")
        print(f"   üìÑ Scaler: {scaler_path.absolute()}")
        print(f"   üìÑ Stats: {stats_path.absolute()}")
        
        try:
            # Charger le mod√®le
            if model_path.exists():
                cls._model = joblib.load(str(model_path))
                print(f"‚úÖ Mod√®le charg√© : {model_path} ({model_path.stat().st_size / 1024:.2f} KB)")
            else:
                print(f"‚ùå Mod√®le non trouv√© : {model_path}")
                print(f"   Fichiers disponibles dans {model_path.parent}: {list(model_path.parent.glob('*')) if model_path.parent.exists() else 'Dossier inexistant'}")
                return False
            
            # Charger le scaler
            if scaler_path.exists():
                cls._scaler = joblib.load(str(scaler_path))
                print(f"‚úÖ Scaler charg√© : {scaler_path} ({scaler_path.stat().st_size / 1024:.2f} KB)")
            else:
                print(f"‚ùå Scaler non trouv√© : {scaler_path}")
                return False
            
            # Charger les statistiques (optionnel)
            if stats_path.exists():
                cls._train_stats = joblib.load(str(stats_path))
                print(f"‚úÖ Statistiques charg√©es : {stats_path}")
            else:
                print(f"‚ÑπÔ∏è Statistiques non trouv√©es (optionnel) : {stats_path}")
                cls._train_stats = None
            
            cls._is_loaded = True
            print("üéâ Mod√®le charg√© avec succ√®s!")
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement du mod√®le : {e}")
            import traceback
            traceback.print_exc()
            cls._is_loaded = False
            return False
    
    @classmethod
    def is_model_loaded(cls):
        """
        V√©rifie si le mod√®le est charg√©
        
        Returns:
            bool: True si le mod√®le est pr√™t
        """
        return cls._is_loaded and cls._model is not None and cls._scaler is not None
    
    @classmethod
    def get_model_info(cls):
        """
        Retourne les informations sur le mod√®le charg√©
        
        Returns:
            dict: Informations sur le mod√®le
        """
        if not cls._is_loaded:
            return {
                'loaded': False,
                'message': 'Mod√®le non charg√©',
                'paths': {
                    'model': str(cls.DEFAULT_MODEL_PATH.absolute()),
                    'scaler': str(cls.DEFAULT_SCALER_PATH.absolute()),
                    'stats': str(cls.DEFAULT_STATS_PATH.absolute()),
                },
                'exists': {
                    'model': cls.DEFAULT_MODEL_PATH.exists(),
                    'scaler': cls.DEFAULT_SCALER_PATH.exists(),
                    'stats': cls.DEFAULT_STATS_PATH.exists(),
                }
            }
        
        return {
            'loaded': True,
            'model_type': type(cls._model).__name__,
            'has_scaler': cls._scaler is not None,
            'has_train_stats': cls._train_stats is not None,
            'paths': {
                'model': str(cls.DEFAULT_MODEL_PATH.absolute()),
                'scaler': str(cls.DEFAULT_SCALER_PATH.absolute()),
                'stats': str(cls.DEFAULT_STATS_PATH.absolute()),
            }
        }
    
    @staticmethod
    def preprocess_transaction(transaction_data, train_stats=None):
        """
        Applique le m√™me preprocessing que lors de l'entra√Ænement
        
        Args:
            transaction_data (dict): Donn√©es de la transaction
            train_stats (dict): Statistiques d'entra√Ænement (optionnel)
            
        Returns:
            pd.DataFrame: Donn√©es preprocess√©es
        """
        # Convertir en DataFrame
        if isinstance(transaction_data, dict):
            df = pd.DataFrame([transaction_data])
        else:
            df = transaction_data.copy()
        
        # Utiliser les stats d'entra√Ænement si disponibles
        if train_stats is None:
            train_stats = PredictionService._train_stats
        
        # 1. Cr√©er l'indicateur de transaction √©lev√©e
        if train_stats and 'percentile_99' in train_stats:
            percentile_99 = train_stats['percentile_99']
        else:
            percentile_99 = 500  # Valeur par d√©faut
        
        df['TransactionAmount_is_high'] = (df['TransactionAmount'] > percentile_99).astype(int)
        
        # 2. Calculer le Z-score
        if train_stats and 'mean' in train_stats and 'std' in train_stats:
            mean = train_stats['mean']
            std = train_stats['std']
        else:
            mean = 100  # Valeur par d√©faut
            std = 200   # Valeur par d√©faut
        
        # √âviter la division par z√©ro
        if std == 0:
            std = 1
        
        df['TransactionAmount_zscore'] = (df['TransactionAmount'] - mean) / std
        
        # 3. Transformation logarithmique
        df['TransactionAmount_log'] = np.log1p(df['TransactionAmount'])
        
        # 4. Cat√©gorisation du montant
        bins = [0, 10, 50, 100, 500, float('inf')]
        df['TransactionAmount_category'] = pd.cut(
            df['TransactionAmount'],
            bins=bins,
            labels=False
        ).fillna(0).astype(int)
        
        return df
    
    @staticmethod
    def prepare_features(transaction_data):
        """
        Pr√©pare les features pour la pr√©diction
        
        Args:
            transaction_data (dict): Donn√©es brutes de la transaction
            
        Returns:
            pd.DataFrame: Features pr√™tes pour le mod√®le
        """
        # Mapping des noms de colonnes (de l'API vers le mod√®le)
        column_mapping = {
            'gender': 'Gender',
            'age': 'Age',
            'house_type_id': 'HouseTypeID',
            'contact_avaliability_id': 'ContactAvaliabilityID',
            'home_country': 'HomeCountry',
            'account_no': 'AccountNo',
            'card_expiry_date': 'CardExpiryDate',
            'transaction_amount': 'TransactionAmount',
            'transaction_country': 'TransactionCountry',
            'large_purchase': 'LargePurchase',
            'product_id': 'ProductID',
            'cif': 'CIF',
            'transaction_currency_code': 'TransactionCurrencyCode'
        }
        
        # Convertir les noms de colonnes
        mapped_data = {}
        for api_name, model_name in column_mapping.items():
            if api_name in transaction_data:
                mapped_data[model_name] = transaction_data[api_name]
            elif model_name in transaction_data:
                mapped_data[model_name] = transaction_data[model_name]
            else:
                # Valeur par d√©faut
                mapped_data[model_name] = 0
        
        # Cr√©er le DataFrame
        df = pd.DataFrame([mapped_data])
        
        # Appliquer le preprocessing
        df = PredictionService.preprocess_transaction(df)
        
        return df
    
    @classmethod
    def predict(cls, transaction_data):
        """
        Pr√©dit si une transaction est frauduleuse
        
        Args:
            transaction_data (dict): Donn√©es de la transaction
            
        Returns:
            dict: R√©sultat de la pr√©diction avec probabilit√©
        """
        # V√©rifier que le mod√®le est charg√©
        if not cls.is_model_loaded():
            return {
                'success': False,
                'error': 'Mod√®le non charg√©. Veuillez charger le mod√®le d\'abord.',
                'prediction': None,
                'probability': None
            }
        
        try:
            # Pr√©parer les features
            features_df = cls.prepare_features(transaction_data)
            
            # Normaliser avec le scaler
            features_scaled = cls._scaler.transform(features_df)
            
            # Faire la pr√©diction
            prediction = cls._model.predict(features_scaled)[0]
            
            # Obtenir les probabilit√©s si disponibles
            if hasattr(cls._model, 'predict_proba'):
                probabilities = cls._model.predict_proba(features_scaled)[0]
                proba_fraud = float(probabilities[1])
                proba_legitimate = float(probabilities[0])
            else:
                proba_fraud = float(prediction)
                proba_legitimate = 1 - proba_fraud
            
            return {
                'success': True,
                'prediction': int(prediction),
                'is_fraud': bool(prediction == 1),
                'label': 'FRAUDE' if prediction == 1 else 'L√âGITIME',
                'probability': {
                    'fraud': round(proba_fraud * 100, 2),
                    'legitimate': round(proba_legitimate * 100, 2)
                },
                'confidence': round(max(proba_fraud, proba_legitimate) * 100, 2)
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'Erreur lors de la pr√©diction : {str(e)}',
                'prediction': None,
                'probability': None
            }
    
    @classmethod
    def predict_batch(cls, transactions_list):
        """
        Pr√©dit pour un batch de transactions
        
        Args:
            transactions_list (list): Liste de dictionnaires de transactions
            
        Returns:
            dict: R√©sultats des pr√©dictions
        """
        if not cls.is_model_loaded():
            return {
                'success': False,
                'error': 'Mod√®le non charg√©',
                'predictions': []
            }
        
        try:
            results = []
            fraud_count = 0
            
            for idx, transaction in enumerate(transactions_list):
                result = cls.predict(transaction)
                result['index'] = idx
                results.append(result)
                
                if result.get('is_fraud'):
                    fraud_count += 1
            
            return {
                'success': True,
                'total': len(transactions_list),
                'fraud_detected': fraud_count,
                'legitimate': len(transactions_list) - fraud_count,
                'fraud_rate': round(fraud_count / len(transactions_list) * 100, 2) if transactions_list else 0,
                'predictions': results
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'Erreur lors de la pr√©diction batch : {str(e)}',
                'predictions': []
            }
    
    @classmethod
    def explain_prediction(cls, transaction_data):
        """
        Explique les facteurs de risque d'une transaction
        
        Args:
            transaction_data (dict): Donn√©es de la transaction
            
        Returns:
            dict: Analyse des facteurs de risque
        """
        risk_factors = []
        risk_score = 0
        
        # Analyser le montant
        amount = transaction_data.get('transaction_amount') or transaction_data.get('TransactionAmount', 0)
        if amount > 500:
            risk_factors.append({
                'factor': 'Montant √©lev√©',
                'value': amount,
                'risk': 'HIGH',
                'description': f'Transaction de {amount}‚Ç¨ sup√©rieure au seuil de 500‚Ç¨'
            })
            risk_score += 30
        elif amount > 200:
            risk_factors.append({
                'factor': 'Montant mod√©r√©-√©lev√©',
                'value': amount,
                'risk': 'MEDIUM',
                'description': f'Transaction de {amount}‚Ç¨ dans la tranche sup√©rieure'
            })
            risk_score += 15
        
        # Analyser l'√¢ge
        age = transaction_data.get('age') or transaction_data.get('Age', 30)
        if age < 18:
            risk_factors.append({
                'factor': '√Çge suspect',
                'value': age,
                'risk': 'HIGH',
                'description': 'Client mineur - v√©rification requise'
            })
            risk_score += 25
        elif age > 80:
            risk_factors.append({
                'factor': 'Client senior',
                'value': age,
                'risk': 'MEDIUM',
                'description': 'Vigilance accrue pour les clients seniors'
            })
            risk_score += 10
        
        # Analyser l'achat large
        large_purchase = transaction_data.get('large_purchase') or transaction_data.get('LargePurchase', 0)
        if large_purchase == 1:
            risk_factors.append({
                'factor': 'Achat important',
                'value': 'Oui',
                'risk': 'MEDIUM',
                'description': 'Transaction marqu√©e comme achat important'
            })
            risk_score += 15
        
        # Analyser le pays de transaction
        home_country = transaction_data.get('home_country') or transaction_data.get('HomeCountry', 1)
        trans_country = transaction_data.get('transaction_country') or transaction_data.get('TransactionCountry', 1)
        if home_country != trans_country:
            risk_factors.append({
                'factor': 'Transaction internationale',
                'value': f'Pays domicile: {home_country}, Pays transaction: {trans_country}',
                'risk': 'MEDIUM',
                'description': 'Transaction effectu√©e dans un pays diff√©rent du domicile'
            })
            risk_score += 20
        
        # D√©terminer le niveau de risque global
        if risk_score >= 50:
            risk_level = 'HIGH'
        elif risk_score >= 25:
            risk_level = 'MEDIUM'
        else:
            risk_level = 'LOW'
        
        return {
            'risk_score': min(risk_score, 100),
            'risk_level': risk_level,
            'factors_count': len(risk_factors),
            'risk_factors': risk_factors,
            'recommendation': 'V√©rification manuelle recommand√©e' if risk_level == 'HIGH' else 'Aucune action requise'
        }